{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get time series for 17 processed features\n",
    "\n",
    "This script is used for generating time series for 17 processed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "# from sklearn.cross_validation import StratifiedShuffleSplit, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(\"..\")\n",
    "# from dataprocessing.util import make_splits\n",
    "\n",
    "def try_making_splits(y, nfold, test_ratio=None):\n",
    "    '''\n",
    "    y: n*n_class\n",
    "        tries to find n splits, where:\n",
    "        size of (train, valid, test) is (nfold-2, 1, 1)\n",
    "        # of samples for one class is (>=1/2, >=0.5*ratio, >=0.5*ratio)\n",
    "    '''\n",
    "    idx_list = np.empty([nfold, 3], dtype=object)\n",
    "    if test_ratio is None:\n",
    "        test_ratio = 1.0 / nfold\n",
    "    n_samples, n_classes = y.shape\n",
    "    i_class_least = np.argmin(np.sum(y, axis=0))\n",
    "    i_trial = 0\n",
    "    print('\\nnew try: ', i_trial,)\n",
    "    cnt = 0\n",
    "    while i_trial < nfold:\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print('{} trials'.format(cnt))\n",
    "        success_flag = True\n",
    "        ss = StratifiedShuffleSplit(n_splits=1,\n",
    "                                    test_size=test_ratio)\n",
    "        for idx_trva, idx_te in ss.split(np.zeros(len(y[:, i_class_least])), y[:, i_class_least]):  # length is only 1 !\n",
    "            for i_class in range(n_classes):\n",
    "                print(f\"non-zero percentage: {np.sum(y[:, i_class])} / {n_samples}\")\n",
    "                te_percent = 1.0 * np.sum(y[idx_te, i_class]) / np.sum(y[:, i_class])\n",
    "                trva_percent = 1.0 * np.sum(y[idx_trva, i_class]) / np.sum(y[:, i_class])\n",
    "                if te_percent < 0.5 * test_ratio or \\\n",
    "                                trva_percent < 0.5 + 0.5 * test_ratio:\n",
    "                    success_flag = False\n",
    "                    print(\"trva-test:\")\n",
    "                    print(i_class, te_percent, trva_percent)\n",
    "                    print(y[idx_te, i_class], y[idx_trva, i_class])\n",
    "                    print(idx_te, idx_trva)\n",
    "                    break\n",
    "            if not success_flag:\n",
    "                break\n",
    "        if not success_flag:\n",
    "            continue\n",
    "        cnt2 = 0\n",
    "        while cnt2 < 1000:\n",
    "            cnt2 += 1\n",
    "            success_flag = True\n",
    "            ss2 = StratifiedShuffleSplit(n_splits=1,\n",
    "                                         test_size=test_ratio * n_samples / len(idx_trva))\n",
    "            for idx_tr_ss2, idx_va_ss2 in ss2.split(np.zeros(len(idx_trva)), y[idx_trva, i_class_least]):  # length is only 1 !\n",
    "                idx_tr = idx_trva[idx_tr_ss2]\n",
    "                idx_va = idx_trva[idx_va_ss2]\n",
    "                for i_class in range(n_classes):\n",
    "                    tr_percent = 1.0 * np.sum(y[idx_tr, i_class]) / np.sum(y[:, i_class])\n",
    "                    va_percent = 1.0 * np.sum(y[idx_va, i_class]) / np.sum(y[:, i_class])\n",
    "                    if va_percent < 0.5 * test_ratio or \\\n",
    "                                    tr_percent < 0.5:\n",
    "                        success_flag = False\n",
    "                        print(\"tr-va:\")\n",
    "                        print(i_class, tr_percent, va_percent)\n",
    "                        break\n",
    "                if not success_flag:\n",
    "                    break\n",
    "            if not success_flag:\n",
    "                continue\n",
    "        if not success_flag:\n",
    "            continue\n",
    "        idx_list[i_trial] = [idx_tr, idx_va, idx_te]\n",
    "        i_trial += 1\n",
    "    return idx_list\n",
    "\n",
    "\n",
    "def make_splits(y, nfold):\n",
    "    if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "        return try_making_splits(y, nfold)\n",
    "    assert nfold > 2\n",
    "    skf = StratifiedKFold(nfold, shuffle=True, random_state=0)\n",
    "    idx_trva_list = []\n",
    "    idx_te_list = []\n",
    "    for idx_tr, idx_te in skf.split(np.zeros(np.array(y).flatten().shape[0]), np.array(y).flatten()):\n",
    "        idx_trva_list.append(idx_tr)\n",
    "        idx_te_list.append(idx_te)\n",
    "\n",
    "    idx_list = np.empty([nfold, 3], dtype=object)\n",
    "    for i in range(nfold):\n",
    "        idx_list[i][0] = np.setdiff1d(idx_trva_list[i], idx_te_list[(i + 1) % nfold], True)\n",
    "        idx_list[i][1] = idx_te_list[(i + 1) % nfold]\n",
    "        idx_list[i][2] = idx_te_list[i]\n",
    "    return idx_list\n",
    "\n",
    "# def get_icd9_subcat_label(icd9_str):\n",
    "#     ss = icd9_str.split('.')[0]\n",
    "#     idx_lb = max(np.where(ss >= subcat_lbs)[0])\n",
    "#     idx_ub = min(np.where(ss[:4] <= subcat_ubs)[0])\n",
    "#     if idx_lb != idx_ub:\n",
    "#         print(idx_lb, idx_ub, icd9_str, ss)\n",
    "#     #assert idx_lb == idx_ub\n",
    "#     return idx_lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters\n",
    "\n",
    "- HRS: Set length of timeseries, unit is hour.\n",
    "- working_path: path where DB_merged_Xhrs.npy, ICD9-Xhrs.npy, AGE_LOS_MORTALITY_Xhrs.npy, ADM_FEATURES_Xhrs.npy, ADM_LABELS_Xhrs.npy are located.\n",
    "- LAB_EVENTS_IDX: indices of features from chartevents and labevents. For these features, we use forward and backward imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Main ####\n",
    "# DATA_NAME = 'mimic319k48h'\n",
    "# Settings for task, model, path, etc\n",
    "# working_path = r'../..'\n",
    "HRS = 24\n",
    "\n",
    "working_path = '/media/data/mimic/hf_admdata_17f/%dhrs/' % HRS\n",
    "# raw_data_path = os.path.join(working_path, 'data', DATA_NAME, 'raw')\n",
    "# processed_data_path = os.path.join(working_path, 'data', DATA_NAME)\n",
    "raw_data_path = working_path\n",
    "processed_data_path = os.path.join(working_path, 'series')\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "\n",
    "LAB_EVENTS_IDX = np.array([0,1,2,3,4,5,7,8,9,10,11,12]) # labevents and chartevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data file\n",
      "load icd9 label file\n",
      "load mor label file\n",
      "load admission features\n",
      "load mortality labels\n",
      "# of samples: 15702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-2d04d61ea2c3>:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_raw_p48 = np.array([np.array(xx, dtype=float)[:,:-2] for xx in data_all])\n",
      "<ipython-input-9-2d04d61ea2c3>:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tsraw_p48 = np.array([np.array(xx, dtype=float)[:,-2] for xx in data_all])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "# of samples > 24 hours: 15702\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "print('load data file')\n",
    "data_all = np.empty([0], dtype=object)\n",
    "for datanpz_file_name in ['DB_merged_%dhrs.npy' % HRS]:\n",
    "    datanpz_file_pathname = os.path.join(raw_data_path,\n",
    "                                         datanpz_file_name)\n",
    "    data_all = np.concatenate((data_all, np.load(datanpz_file_pathname, allow_pickle=True)))\n",
    "\n",
    "print('load icd9 label file')\n",
    "label_icd9_all = np.empty([0], dtype=object)\n",
    "for label_icd9_npz_file_name in ['ICD9-%dhrs.npy' % HRS]:\n",
    "    label_icd9_npz_file_pathname = os.path.join(raw_data_path, \n",
    "                                                label_icd9_npz_file_name)\n",
    "    label_icd9_all = np.concatenate((label_icd9_all, \n",
    "                                    np.load(label_icd9_npz_file_pathname, allow_pickle=True)))\n",
    "\n",
    "# print('load icd9 subcat list file')\n",
    "# subcat_lbs = []\n",
    "# subcat_ubs = []\n",
    "# with open(os.path.join(raw_data_path, 'ICD9_subcat.csv'), 'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         subcat_id, subcat_lb, subcat_ub = line.split(',')\n",
    "#         subcat_lbs.append(subcat_lb)\n",
    "#         subcat_ubs.append(subcat_ub)\n",
    "#     subcat_lbs = np.array(subcat_lbs)\n",
    "#     subcat_ubs = np.array(subcat_ubs)\n",
    "\n",
    "print('load mor label file')\n",
    "label_mor_all = None\n",
    "for label_mor_npz_file_name in ['AGE_LOS_MORTALITY_%dhrs.npy' % HRS]:\n",
    "    label_mor_npz_file_pathname = os.path.join(raw_data_path,\n",
    "                                               label_mor_npz_file_name)\n",
    "    if label_mor_all is None:\n",
    "        label_mor_all = np.load(label_mor_npz_file_pathname, allow_pickle=True)\n",
    "    else:\n",
    "        label_mor_all = np.concatenate((label_mor_all, \n",
    "                                        np.load(label_mor_npz_file_pathname, allow_pickle=True)))\n",
    "        \n",
    "print('load admission features')\n",
    "adm_features_all = np.load(os.path.join(raw_data_path, 'ADM_FEATURES_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "\n",
    "print('load mortality labels')\n",
    "adm_labels_all = np.load(os.path.join(raw_data_path, 'ADM_LABELS_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "\n",
    "N_all = len(data_all)\n",
    "print('# of samples:', N_all)\n",
    "# get per-frame samples;\n",
    "# imputed-normed-ep (imputation here):    \n",
    "#               ep_tdata_raw, ep_tdata: N * [ti * D]\n",
    "#               ep_tdata_mean, ep_tdata_std: D\n",
    "# normed-ep:    X_t, X_t_mask, deltaT_t: N * [ti * D]\n",
    "#               T_t: N * [ti]\n",
    "X_raw_p48 = np.array([np.array(xx, dtype=float)[:,:-2] for xx in data_all])\n",
    "tsraw_p48 = np.array([np.array(xx, dtype=float)[:,-2] for xx in data_all])\n",
    "del data_all\n",
    "\n",
    "idx_x = np.where([(tt[-1] - tt[0]) > 1.0*60*60*HRS for tt in tsraw_p48])[0]\n",
    "idx_x2 = np.where([(tt[-1] - tt[0]) <= 1.0*60*60*HRS for tt in tsraw_p48])[0]\n",
    "print(idx_x2)\n",
    "N = len(idx_x)\n",
    "print('# of samples > %s hours:' % (HRS), N)\n",
    "assert N_all == N\n",
    "X_raw = X_raw_p48[idx_x]\n",
    "tsraw = tsraw_p48[idx_x]\n",
    "label_icd9_all = label_icd9_all[idx_x]\n",
    "label_mor_all = label_mor_all[idx_x]\n",
    "adm_features_all = adm_features_all[idx_x]\n",
    "adm_labels_all = adm_labels_all[idx_x]\n",
    "\n",
    "for i_n in range(N):\n",
    "    #print i_n\n",
    "    if i_n % 20 == 0:\n",
    "        print('.', end='')\n",
    "        sys.stdout.flush()\n",
    "    for i_t in range(len(X_raw[i_n])):\n",
    "        for i_d in range(len(X_raw[i_n][i_t])):\n",
    "            if X_raw[i_n][i_t][i_d] is None:\n",
    "                X_raw[i_n][i_t][i_d] = np.nan\n",
    "X_raw_all = np.concatenate(X_raw)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  7229.,  15869.,  18329.,  21089.,  21329.,  25889.,  26669.,\n",
      "         29069.,  29189.,  29489.,  30329.,  30389.,  31289.,  32189.,\n",
      "         32969.,  33089.,  33989.,  34889.,  35129.,  35249.,  37289.,\n",
      "         38489.,  38609.,  40049.,  42089.,  45689.,  46709.,  49289.,\n",
      "         49769.,  52889.,  56489.,  60089.,  63689.,  67289.,  67709.,\n",
      "         70889.,  74489.,  75269.,  78089.,  81089.,  81689.,  85289.,\n",
      "         85889.,  88889.,  90689.,  91589.,  92069.,  92489.,  93389.,\n",
      "         94289.,  95189.,  96089.,  96629.,  99689., 103289., 106889.,\n",
      "        110489., 111389., 114089., 117689., 118589., 120089., 121289.,\n",
      "        124889., 125369., 125609., 128489., 132089., 132209., 135689.,\n",
      "        135989., 139289., 139829., 142889., 146489., 147209., 150089.,\n",
      "        150749., 153689., 157289., 160889., 164489., 165449., 175289.,\n",
      "        176189., 177089., 177989., 178229., 178889., 182489., 186089.,\n",
      "        189689., 189809., 193289., 196889., 200489., 204089., 207689.,\n",
      "        211289., 214889., 236489., 321989.])\n",
      " array([-11663.,   -803.,    637.,   2977.,   5497.,   5557.,   5857.,\n",
      "          6337.,   6757.,   6937.,   7657.,   9457.,  10357.,  11257.,\n",
      "         14857.,  18337.,  18457.,  20257.,  20377.,  22057.,  25657.,\n",
      "         29257.,  32857.,  33997.,  34957.,  36457.,  40057.,  43657.,\n",
      "         44797.,  47257.,  50857.,  54457.,  58057.,  59977.,  61657.,\n",
      "         64057.,  65257.,  68857.,  72457.,  76357.,  81337.,  81457.,\n",
      "         82357.,  82837.,  83257.,  83437.,  84157.,  85057.,  86857.,\n",
      "         87277.,  88657.,  90457.,  92257.,  94057.,  96937.,  97657.,\n",
      "         97717., 101257., 104857., 108457., 112057., 115657., 119257.,\n",
      "        121057., 122857., 125377., 126457., 130057., 133657., 133897.,\n",
      "        137257., 140857., 142357., 144457., 148057., 151657., 155257.,\n",
      "        158857., 162457., 166057., 169657., 173257., 176857., 180457.,\n",
      "        180697., 180997., 184057., 184417., 187657., 188017., 191257.,\n",
      "        191617., 194857., 195277., 198457., 198817., 202057., 202417.,\n",
      "        205657., 206917., 209257., 210577., 212857., 214177., 216457.,\n",
      "        217777., 220057., 221377., 223657., 224977., 227257., 227797.,\n",
      "        228577., 230857., 232177., 234457., 235777., 238057., 239377.,\n",
      "        241657., 242977., 245257., 246577., 248857., 250177., 252457.,\n",
      "        253777., 256057., 257377., 259657., 260257., 261037., 263257.,\n",
      "        263797., 266857., 269977., 270457., 274057., 276637., 277657.,\n",
      "        281257., 283897., 284857., 286657., 288457., 292057., 293437.,\n",
      "        294577., 295657., 299257., 302857., 306457., 323857., 432817.,\n",
      "        508897., 613057.])\n",
      " array([-20797.,  -8857.,   3803.,   4403.,   4643.,   4943.,   5903.,\n",
      "          7343.,   7403.,   7703.,   7763.,   8303.,   9203.,  10103.,\n",
      "         11003.,  11543.,  11903.,  12803.,  13703.,  14603.,  14843.,\n",
      "         16643.,  18203.,  18383.,  19103.,  21803.,  23963.,  25403.,\n",
      "         27023.,  29003.,  31943.,  32603.,  35903.,  36203.,  39803.,\n",
      "         43403.,  43583.,  47003.,  50603.,  55583.,  58943.,  63143.,\n",
      "         65903.,  67403.,  81983.,  83963.,  84083.,  84563.,  84683.,\n",
      "         85343.,  86603.,  86903.,  87203.,  87503.,  87623.,  87803.,\n",
      "         88403.,  89303.,  89723.,  90203.,  92663.,  92723.,  93803.,\n",
      "         93983.,  94523.,  94703.,  95603.,  97403.,  97823., 101003.,\n",
      "        101723., 104603., 104663., 108143., 108203., 111803., 115403.,\n",
      "        116963., 119003., 119603., 121223., 121763., 122603., 126203.,\n",
      "        127283., 129803., 131903., 133403., 135143., 137003., 140603.,\n",
      "        144203., 147803., 148703., 151403., 155003., 155843., 158603.,\n",
      "        164543., 164663., 165803., 169403., 173003., 174743., 176603.,\n",
      "        176663., 180203., 180383., 183803., 183863., 187403., 191003.,\n",
      "        194603., 195083., 198203., 201803., 205403., 205763., 209003.,\n",
      "        212603., 215243., 216203., 219803., 221663., 223403., 224783.,\n",
      "        225683., 227003., 227783., 230603., 234203., 234923., 235163.,\n",
      "        237803., 241403., 242903., 243263., 245003., 247103., 248603.,\n",
      "        249623., 252203., 255743., 255803., 258443., 259403., 260783.,\n",
      "        263003., 263303., 266603., 270203., 271163., 273803., 277403.,\n",
      "        281003., 284603., 284663., 287183., 288203., 290003., 291803.,\n",
      "        293183., 295403., 299003., 299363., 302603., 306203., 306923.,\n",
      "        307043., 309803., 313403., 317003., 320603., 324203., 327803.,\n",
      "        331403., 382583., 468383., 523343., 572603., 646703.])         ...\n",
      " array([1.696000e+03, 2.956000e+03, 3.496000e+03, 4.396000e+03,\n",
      "        5.296000e+03, 7.096000e+03, 1.069600e+04, 1.429600e+04,\n",
      "        1.789600e+04, 2.149600e+04, 2.509600e+04, 2.869600e+04,\n",
      "        3.061600e+04, 3.229600e+04, 3.589600e+04, 3.949600e+04,\n",
      "        4.309600e+04, 4.669600e+04, 5.029600e+04, 5.389600e+04,\n",
      "        5.749600e+04, 6.109600e+04, 6.469600e+04, 6.769600e+04,\n",
      "        7.189600e+04, 7.909600e+04, 8.629600e+04, 9.349600e+04,\n",
      "        9.709600e+04, 1.006960e+05, 1.042960e+05, 1.078960e+05,\n",
      "        1.114960e+05, 1.150960e+05, 1.186960e+05, 1.222960e+05,\n",
      "        1.258960e+05, 1.294960e+05, 1.330960e+05, 1.336960e+05,\n",
      "        1.366960e+05, 1.402960e+05, 1.438960e+05, 1.474960e+05,\n",
      "        1.510960e+05, 1.513960e+05, 1.516960e+05, 1.546960e+05,\n",
      "        1.582960e+05, 1.618960e+05, 1.654960e+05, 1.690960e+05,\n",
      "        1.726960e+05, 1.762960e+05, 1.798960e+05, 1.834960e+05,\n",
      "        1.870960e+05, 1.906960e+05, 1.942960e+05, 1.978960e+05,\n",
      "        2.014960e+05, 2.050960e+05, 2.086960e+05, 2.122960e+05,\n",
      "        2.127160e+05, 2.221960e+05, 2.312560e+05, 2.338960e+05,\n",
      "        2.386360e+05, 2.397160e+05, 2.416960e+05, 2.446960e+05,\n",
      "        2.455960e+05, 2.464960e+05, 2.467360e+05, 2.473960e+05,\n",
      "        2.475760e+05, 2.476960e+05, 2.482960e+05, 2.491960e+05,\n",
      "        2.494960e+05, 2.500360e+05, 2.500960e+05, 2.509960e+05,\n",
      "        2.518960e+05, 2.521360e+05, 2.527960e+05, 2.536960e+05,\n",
      "        2.545960e+05, 2.554960e+05, 2.563960e+05, 2.572960e+05,\n",
      "        2.578960e+05, 2.581960e+05, 2.590960e+05, 2.599960e+05,\n",
      "        2.608960e+05, 2.617960e+05, 2.626960e+05, 2.635960e+05,\n",
      "        2.636560e+05, 2.644960e+05, 2.653960e+05, 2.662360e+05,\n",
      "        2.662960e+05, 2.680960e+05, 2.698960e+05, 2.716960e+05,\n",
      "        2.734960e+05, 2.770960e+05, 2.779960e+05, 2.794360e+05,\n",
      "        2.806960e+05, 2.842960e+05, 2.878960e+05, 2.914960e+05,\n",
      "        2.950960e+05, 2.966560e+05, 2.974360e+05, 2.986960e+05,\n",
      "        3.004960e+05, 3.022960e+05, 3.058960e+05, 3.094960e+05,\n",
      "        3.121960e+05, 3.130960e+05, 3.166960e+05, 3.186160e+05,\n",
      "        3.202960e+05, 3.238960e+05, 3.274960e+05, 3.310960e+05,\n",
      "        3.337360e+05, 3.346960e+05, 3.382960e+05, 3.418960e+05,\n",
      "        3.454960e+05, 3.457960e+05, 3.526960e+05, 3.540760e+05,\n",
      "        3.562960e+05, 3.598960e+05, 3.625960e+05, 3.634960e+05,\n",
      "        3.670960e+05, 3.679960e+05, 3.706960e+05, 3.742960e+05,\n",
      "        3.778960e+05, 3.814960e+05, 3.831160e+05, 3.847960e+05,\n",
      "        3.850960e+05, 3.886960e+05, 3.922960e+05, 3.958960e+05,\n",
      "        3.994960e+05, 4.030960e+05, 4.066960e+05, 4.102960e+05,\n",
      "        4.120960e+05, 4.134760e+05, 4.138960e+05, 4.174960e+05,\n",
      "        4.210960e+05, 4.246960e+05, 4.282960e+05, 4.291960e+05,\n",
      "        4.295560e+05, 4.300960e+05, 4.318960e+05, 4.331560e+05,\n",
      "        4.354960e+05, 4.390960e+05, 4.426960e+05, 4.462960e+05,\n",
      "        4.484560e+05, 4.498960e+05, 4.534960e+05, 4.570960e+05,\n",
      "        4.606960e+05, 4.642960e+05, 4.645960e+05, 4.656760e+05,\n",
      "        4.678960e+05, 4.714960e+05, 4.750960e+05, 4.786960e+05,\n",
      "        4.822960e+05, 4.858960e+05, 4.894960e+05, 4.912960e+05,\n",
      "        4.930960e+05, 4.950160e+05, 4.966960e+05, 5.002960e+05,\n",
      "        5.038960e+05, 5.074960e+05, 5.110960e+05, 5.146960e+05,\n",
      "        5.182960e+05, 5.197960e+05, 5.218960e+05, 5.244160e+05,\n",
      "        5.254960e+05, 5.290960e+05, 5.326960e+05, 5.362960e+05,\n",
      "        5.388160e+05, 5.398960e+05, 5.434960e+05, 5.470960e+05,\n",
      "        5.506960e+05, 5.521960e+05, 5.522560e+05, 5.523760e+05,\n",
      "        5.533960e+05, 5.542960e+05, 5.578960e+05, 5.614960e+05,\n",
      "        5.650960e+05, 5.686960e+05, 5.719360e+05, 5.722960e+05,\n",
      "        5.758960e+05, 5.776960e+05, 5.778160e+05, 5.794960e+05,\n",
      "        5.815960e+05, 5.828560e+05, 5.830960e+05, 5.866960e+05,\n",
      "        5.901760e+05, 5.902960e+05, 5.938960e+05, 5.974960e+05,\n",
      "        5.981560e+05, 5.992960e+05, 6.010960e+05, 6.046960e+05,\n",
      "        6.082960e+05, 6.118960e+05, 6.154960e+05, 6.190960e+05,\n",
      "        6.226960e+05, 6.228160e+05, 6.244960e+05, 6.262960e+05,\n",
      "        6.280960e+05, 6.298960e+05, 6.326560e+05, 6.334960e+05,\n",
      "        6.370960e+05, 6.401560e+05, 6.402760e+05, 6.406960e+05,\n",
      "        6.442960e+05, 6.478960e+05, 6.514960e+05, 6.550960e+05,\n",
      "        6.586960e+05, 6.613960e+05, 6.622960e+05, 6.658960e+05,\n",
      "        6.682960e+05, 6.694960e+05, 6.721960e+05, 6.730960e+05,\n",
      "        6.736960e+05, 6.748960e+05, 6.757960e+05, 6.766960e+05,\n",
      "        6.775960e+05, 6.802960e+05, 6.838960e+05, 6.862960e+05,\n",
      "        6.874960e+05, 6.910960e+05, 6.928960e+05, 6.946960e+05,\n",
      "        6.951160e+05, 6.982960e+05, 7.018960e+05, 7.054960e+05,\n",
      "        7.090960e+05, 7.112560e+05, 7.126960e+05, 7.162960e+05,\n",
      "        7.198960e+05, 7.234960e+05, 7.242760e+05, 7.244560e+05,\n",
      "        7.270960e+05, 7.306960e+05, 7.342960e+05, 7.414960e+05,\n",
      "        7.450960e+05, 7.486960e+05, 7.513960e+05, 7.522960e+05,\n",
      "        7.531960e+05, 7.558960e+05, 7.575160e+05, 7.576960e+05,\n",
      "        7.594960e+05, 7.630960e+05, 7.666960e+05, 7.702960e+05,\n",
      "        7.738960e+05, 7.748560e+05, 7.774960e+05, 7.810960e+05,\n",
      "        7.846960e+05, 7.882960e+05, 7.918960e+05, 7.954960e+05,\n",
      "        7.962160e+05, 7.990960e+05, 8.026960e+05, 8.062960e+05,\n",
      "        8.098960e+05, 8.105560e+05, 8.123560e+05, 8.134960e+05,\n",
      "        8.170960e+05, 8.206960e+05, 8.242960e+05, 8.271160e+05,\n",
      "        8.278960e+05, 8.314960e+05, 8.350960e+05, 8.386960e+05,\n",
      "        8.404960e+05, 8.422960e+05, 8.425960e+05, 8.440960e+05,\n",
      "        8.458960e+05, 8.467960e+05, 8.494960e+05, 8.530960e+05,\n",
      "        8.553760e+05, 8.566960e+05, 8.602960e+05, 8.638960e+05,\n",
      "        8.674960e+05, 8.710960e+05, 8.743960e+05, 8.746960e+05,\n",
      "        8.772760e+05, 8.782960e+05, 8.818960e+05, 8.854960e+05,\n",
      "        8.890960e+05, 8.926960e+05, 8.962960e+05, 8.974960e+05,\n",
      "        8.978560e+05, 8.998960e+05, 9.034960e+05, 9.070960e+05,\n",
      "        9.142960e+05, 9.178960e+05, 9.205960e+05, 9.214960e+05,\n",
      "        9.250960e+05, 9.276160e+05, 9.286960e+05, 9.322960e+05,\n",
      "        9.358960e+05, 9.376960e+05, 9.378760e+05, 9.394960e+05,\n",
      "        9.412960e+05, 9.430960e+05, 9.466960e+05, 9.484960e+05,\n",
      "        9.502960e+05, 9.511360e+05, 9.529960e+05, 9.538960e+05,\n",
      "        9.574960e+05, 9.610960e+05, 9.646960e+05, 9.657760e+05,\n",
      "        9.682960e+05, 9.718960e+05, 9.754960e+05, 9.772960e+05,\n",
      "        9.790960e+05, 9.826960e+05, 9.846760e+05, 9.859960e+05,\n",
      "        9.862960e+05, 9.898960e+05, 9.934960e+05, 9.970960e+05,\n",
      "        1.000696e+06, 1.003576e+06, 1.004296e+06, 1.007896e+06,\n",
      "        1.011496e+06, 1.013296e+06, 1.015096e+06, 1.018696e+06,\n",
      "        1.020436e+06, 1.022296e+06, 1.024036e+06, 1.024096e+06,\n",
      "        1.024996e+06, 1.025896e+06, 1.029496e+06, 1.033096e+06,\n",
      "        1.034896e+06, 1.036696e+06, 1.040296e+06, 1.043896e+06,\n",
      "        1.047496e+06, 1.047676e+06, 1.051096e+06, 1.054696e+06,\n",
      "        1.058296e+06, 1.061896e+06, 1.065496e+06, 1.069096e+06,\n",
      "        1.072696e+06, 1.074796e+06, 1.076296e+06, 1.077916e+06,\n",
      "        1.079896e+06, 1.083496e+06, 1.087096e+06, 1.090696e+06,\n",
      "        1.094296e+06, 1.097896e+06, 1.100596e+06, 1.101496e+06,\n",
      "        1.105096e+06, 1.106056e+06, 1.108696e+06, 1.112296e+06,\n",
      "        1.115896e+06, 1.119496e+06, 1.120156e+06, 1.123096e+06,\n",
      "        1.126696e+06, 1.130296e+06, 1.133896e+06, 1.137496e+06,\n",
      "        1.138516e+06, 1.141096e+06, 1.144696e+06, 1.148296e+06,\n",
      "        1.151896e+06, 1.155496e+06, 1.156336e+06, 1.159096e+06,\n",
      "        1.162696e+06, 1.166296e+06, 1.169896e+06, 1.173496e+06,\n",
      "        1.177096e+06, 1.178896e+06, 1.180696e+06, 1.182496e+06,\n",
      "        1.184296e+06, 1.187896e+06, 1.191496e+06, 1.193056e+06,\n",
      "        1.195096e+06, 1.195996e+06, 1.196896e+06, 1.197796e+06,\n",
      "        1.198696e+06, 1.200496e+06, 1.201396e+06, 1.201816e+06,\n",
      "        1.202296e+06, 1.205896e+06, 1.209496e+06, 1.213096e+06,\n",
      "        1.216696e+06, 1.220296e+06, 1.223896e+06, 1.227496e+06,\n",
      "        1.231096e+06, 1.234696e+06, 1.238296e+06, 1.241896e+06,\n",
      "        1.245496e+06, 1.246396e+06, 1.246636e+06, 1.249096e+06,\n",
      "        1.251676e+06, 1.252696e+06, 1.256296e+06, 1.259896e+06,\n",
      "        1.263496e+06, 1.267096e+06, 1.270696e+06, 1.274296e+06,\n",
      "        1.276276e+06, 1.277896e+06, 1.281496e+06, 1.285096e+06,\n",
      "        1.288696e+06, 1.292296e+06, 1.295896e+06, 1.299496e+06,\n",
      "        1.301296e+06, 1.303096e+06, 1.306696e+06, 1.307596e+06,\n",
      "        1.310296e+06, 1.313896e+06, 1.317496e+06, 1.321096e+06,\n",
      "        1.324696e+06, 1.328296e+06, 1.329136e+06, 1.331896e+06,\n",
      "        1.335496e+06, 1.337296e+06, 1.339096e+06, 1.346296e+06,\n",
      "        1.349896e+06, 1.353496e+06, 1.355896e+06, 1.357096e+06,\n",
      "        1.360696e+06, 1.364296e+06, 1.367896e+06, 1.371496e+06,\n",
      "        1.375096e+06, 1.378696e+06, 1.382296e+06, 1.384876e+06,\n",
      "        1.385896e+06, 1.389496e+06, 1.393096e+06, 1.396696e+06,\n",
      "        1.400296e+06, 1.403596e+06, 1.403896e+06, 1.405996e+06,\n",
      "        1.407496e+06, 1.411096e+06, 1.412896e+06, 1.414696e+06,\n",
      "        1.418296e+06, 1.421896e+06, 1.425496e+06, 1.432696e+06,\n",
      "        1.436296e+06, 1.439896e+06, 1.440196e+06, 1.443496e+06,\n",
      "        1.447096e+06, 1.448956e+06, 1.450636e+06, 1.450696e+06,\n",
      "        1.454296e+06, 1.457896e+06, 1.461496e+06, 1.465096e+06,\n",
      "        1.468696e+06, 1.472296e+06, 1.474096e+06, 1.475896e+06,\n",
      "        1.477096e+06, 1.479496e+06, 1.483096e+06, 1.486696e+06,\n",
      "        1.490296e+06, 1.493896e+06, 1.497496e+06, 1.501096e+06,\n",
      "        1.501996e+06, 1.504696e+06, 1.508296e+06, 1.511896e+06,\n",
      "        1.515496e+06, 1.519096e+06, 1.522696e+06, 1.526296e+06,\n",
      "        1.529896e+06, 1.531096e+06, 1.533496e+06, 1.537096e+06,\n",
      "        1.538896e+06, 1.540696e+06, 1.543696e+06, 1.544296e+06,\n",
      "        1.544536e+06, 1.544896e+06, 1.545196e+06, 1.546096e+06,\n",
      "        1.547896e+06, 1.551496e+06, 1.555096e+06, 1.558696e+06,\n",
      "        1.562296e+06, 1.565896e+06, 1.568956e+06, 1.569496e+06,\n",
      "        1.573096e+06, 1.576696e+06, 1.580296e+06, 1.583896e+06,\n",
      "        1.587496e+06, 1.591096e+06, 1.594696e+06, 1.598296e+06,\n",
      "        1.605496e+06, 1.609096e+06, 1.612696e+06, 1.616296e+06,\n",
      "        1.619896e+06, 1.623496e+06, 1.623796e+06, 1.624396e+06,\n",
      "        1.624696e+06, 1.624996e+06, 1.625296e+06, 1.625416e+06,\n",
      "        1.625476e+06, 1.625716e+06, 1.627096e+06, 1.630396e+06,\n",
      "        1.630696e+06, 1.634296e+06, 1.636096e+06, 1.637896e+06,\n",
      "        1.638976e+06, 1.641496e+06, 1.645096e+06, 1.648696e+06,\n",
      "        1.652296e+06, 1.655416e+06, 1.655896e+06, 1.659496e+06,\n",
      "        1.663096e+06, 1.666696e+06, 1.670296e+06, 1.673896e+06,\n",
      "        1.674196e+06, 1.674796e+06, 1.677496e+06, 1.681096e+06,\n",
      "        1.684696e+06, 1.688296e+06, 1.691896e+06, 1.695496e+06,\n",
      "        1.699096e+06, 1.702696e+06, 1.706296e+06, 1.707196e+06,\n",
      "        1.707496e+06, 1.708096e+06, 1.709896e+06, 1.713496e+06,\n",
      "        1.717096e+06, 1.720696e+06, 1.724296e+06, 1.725796e+06,\n",
      "        1.727896e+06, 1.731496e+06, 1.735096e+06, 1.738696e+06,\n",
      "        1.742296e+06, 1.745896e+06, 1.746736e+06, 1.749496e+06,\n",
      "        1.753096e+06, 1.756696e+06, 1.760296e+06, 1.763056e+06,\n",
      "        1.763896e+06, 1.765036e+06, 1.767496e+06, 1.771096e+06,\n",
      "        1.774696e+06, 1.778296e+06, 1.781896e+06, 1.785496e+06,\n",
      "        1.789096e+06, 1.792696e+06, 1.796296e+06, 1.799896e+06,\n",
      "        1.803496e+06, 1.807096e+06, 1.810696e+06, 1.814296e+06,\n",
      "        1.817896e+06, 1.821496e+06, 1.825096e+06, 1.828696e+06,\n",
      "        1.832296e+06, 1.834096e+06, 1.835896e+06, 1.836856e+06,\n",
      "        1.839496e+06, 1.843096e+06, 1.846696e+06, 1.850296e+06,\n",
      "        1.853896e+06, 1.857496e+06, 1.861096e+06, 1.864696e+06,\n",
      "        1.868296e+06, 1.871896e+06, 1.875496e+06, 1.879096e+06,\n",
      "        1.882696e+06, 1.886296e+06, 1.889896e+06, 1.893496e+06,\n",
      "        1.896256e+06, 1.897096e+06, 1.900696e+06, 1.904296e+06,\n",
      "        1.907896e+06, 1.911496e+06, 1.915096e+06, 1.918696e+06,\n",
      "        1.922296e+06, 1.925896e+06, 1.929496e+06, 1.933096e+06,\n",
      "        1.935016e+06, 1.936696e+06, 1.940296e+06, 1.943896e+06,\n",
      "        1.947496e+06, 1.951096e+06, 1.954696e+06, 1.958296e+06,\n",
      "        1.961896e+06, 1.965496e+06, 1.969096e+06, 1.972696e+06,\n",
      "        1.976296e+06, 1.979896e+06, 1.983496e+06, 1.987096e+06,\n",
      "        1.990696e+06, 1.994296e+06, 1.997896e+06, 2.001496e+06,\n",
      "        2.005096e+06, 2.008696e+06, 2.012296e+06, 2.015896e+06,\n",
      "        2.019496e+06, 2.023096e+06, 2.026036e+06, 2.026696e+06,\n",
      "        2.030296e+06, 2.037496e+06, 2.041096e+06, 2.044696e+06,\n",
      "        2.048296e+06, 2.051896e+06, 2.055496e+06, 2.059096e+06,\n",
      "        2.062696e+06, 2.066296e+06, 2.069896e+06, 2.073496e+06,\n",
      "        2.077096e+06, 2.080696e+06, 2.084296e+06, 2.087896e+06,\n",
      "        2.095096e+06, 2.102296e+06, 2.105896e+06, 2.109496e+06,\n",
      "        2.116696e+06])\n",
      " array([  -759.,   5481.,   8901.,  10461.,  11361.,  13821.,  14121.,\n",
      "         14421.,  14781.,  15021.,  15921.,  16821.,  17721.,  18621.,\n",
      "         19521.,  20421.,  21321.,  22221.,  23121.,  23421.,  24021.,\n",
      "         24921.,  25821.,  26721.,  27381.,  27621.,  28521.,  30321.,\n",
      "         32121.,  34701.,  35721.,  39321.,  42921.,  46521.,  47121.,\n",
      "         48321.,  50121.,  52641.,  53721.,  55521.,  57321.,  60921.,\n",
      "         64521.,  66321.,  68121.,  69921.,  71721.,  75321.,  78921.,\n",
      "         82521.,  86121.,  89721., 152421., 252621., 323721., 339021.])\n",
      " array([-5.5300e+03,  2.3000e+02,  3.5000e+02,  4.7000e+02,  3.5300e+03,\n",
      "         7.1300e+03,  1.0730e+04,  1.4330e+04,  1.7930e+04,  2.1530e+04,\n",
      "         2.5130e+04,  2.8730e+04,  2.8790e+04,  3.1010e+04,  3.2330e+04,\n",
      "         3.5930e+04,  3.8990e+04,  3.9530e+04,  4.3130e+04,  4.6730e+04,\n",
      "         4.9310e+04,  5.0330e+04,  5.3930e+04,  5.7530e+04,  5.9330e+04,\n",
      "         6.0350e+04,  6.1130e+04,  6.2930e+04,  6.3830e+04,  6.4730e+04,\n",
      "         6.5630e+04,  6.5750e+04,  6.8330e+04,  7.1930e+04,  7.2110e+04,\n",
      "         7.5530e+04,  7.9130e+04,  8.2730e+04,  8.3330e+04,  8.6330e+04,\n",
      "         8.9930e+04,  9.0950e+04,  9.3530e+04,  9.4670e+04,  9.7130e+04,\n",
      "         1.0073e+05,  1.0433e+05,  1.0439e+05,  1.0793e+05,  1.1153e+05,\n",
      "         1.1513e+05,  1.1519e+05,  1.1873e+05,  1.1897e+05,  1.2233e+05,\n",
      "         1.2593e+05,  1.2953e+05,  1.3313e+05,  1.3673e+05,  1.4033e+05,\n",
      "         1.4393e+05,  1.4753e+05,  1.5113e+05,  1.5473e+05,  1.5833e+05,\n",
      "         1.6193e+05,  1.6553e+05,  1.6913e+05,  1.7273e+05,  1.7633e+05,\n",
      "         1.7993e+05,  1.8353e+05,  1.8713e+05,  1.9073e+05,  1.9433e+05,\n",
      "         1.9793e+05,  2.0153e+05,  2.0159e+05,  2.0513e+05,  2.0561e+05,\n",
      "         2.0873e+05,  2.0933e+05,  2.0963e+05,  2.1233e+05,  2.1593e+05,\n",
      "         2.1953e+05,  2.2313e+05,  2.2673e+05,  2.3033e+05,  2.3051e+05,\n",
      "         2.3393e+05,  2.3753e+05,  2.4113e+05,  2.4473e+05,  2.4833e+05,\n",
      "         2.5193e+05,  2.5553e+05,  2.5913e+05,  2.6273e+05,  2.6633e+05,\n",
      "         2.6993e+05,  2.7353e+05,  2.7713e+05,  2.8073e+05,  2.8433e+05,\n",
      "         2.8793e+05,  2.8799e+05,  2.9153e+05,  2.9321e+05,  2.9513e+05,\n",
      "         2.9873e+05,  3.0233e+05,  3.0593e+05,  3.0953e+05,  3.1313e+05,\n",
      "         3.1673e+05,  3.2033e+05,  3.2093e+05,  3.2393e+05,  3.2753e+05])]\n"
     ]
    }
   ],
   "source": [
    "print(tsraw_p48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get mr and kept idx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-39e47b66fd6a>:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_raw_kept = np.array([xx[:, keep_val_idx] for xx in X_raw])\n"
     ]
    }
   ],
   "source": [
    "# remove the columns with less observations\n",
    "print('get mr and kept idx')\n",
    "val_mr = np.sum(np.isnan(X_raw_all), axis=0) * 1.0 / X_raw_all.shape[0]\n",
    "keep_val_idx = val_mr < 1-5e-4\n",
    "keep_val_idx_list = np.where(keep_val_idx)\n",
    "X_raw_all_kept = X_raw_all[:,keep_val_idx]\n",
    "X_raw_kept = np.array([xx[:, keep_val_idx] for xx in X_raw])\n",
    "lab_events_idx = LAB_EVENTS_IDX\n",
    "\n",
    "del X_raw_all\n",
    "del X_raw\n",
    "\n",
    "# X_raw_all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean value in the first HRS hours, used for SuperLearner\n",
    "# First get the mean of pao2 and fio2, then calc the ratio!!!\n",
    "PAO2_VAR = 4\n",
    "FIO2_VAR = 5\n",
    "RATIO_VAR = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge time series every 5 minutes\n",
    "\n",
    "We merge the data in time series every 5 minutes by using the average value of all values in the 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get mean and std for tdata\n",
      "get X_new and t_new\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-4a10af6be25c>:32: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(X_raw_kept[i][t:t1,:], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "print('get mean and std for tdata')\n",
    "n_temporal_var = X_raw_all_kept.shape[1]    # last frame is time t in seconds\n",
    "ep_tdata_mean = np.nanmean(X_raw_all_kept, axis=0)\n",
    "ep_tdata_std = np.nanstd(X_raw_all_kept, axis=0)\n",
    "del X_raw_all_kept\n",
    "\n",
    "# get ep data with mask and deltaT\n",
    "# 0-mean, 1-std, merge observations within 5 mins\n",
    "merging_mins = 5\n",
    "print('get X_new and t_new')\n",
    "X_new = np.empty([N], dtype=object)\n",
    "t_new = np.empty([N], dtype=object)\n",
    "for i in range(N):\n",
    "    if i % 20 == 0:\n",
    "        print('.',end='')\n",
    "        sys.stdout.flush()\n",
    "    tsraw[i] = tsraw[i].flatten()\n",
    "    t = 0\n",
    "    X_new[i] = []\n",
    "    t_new[i] = []\n",
    "    while t < len(tsraw[i]):\n",
    "        t1 = t+1\n",
    "        while t1 < len(tsraw[i]) and tsraw[i][t1] - tsraw[i][t] <= merging_mins*60:\n",
    "            t1 += 1\n",
    "        # merge [t:t1]\n",
    "#         X_new[i].append(\n",
    "#             (np.nanmean(X_raw_kept[i][t:t1,:], axis=0) - ep_tdata_mean) \\\n",
    "#                 /ep_tdata_std\n",
    "#             )\n",
    "        # Here we do not normalize the data!!!\n",
    "        X_new[i].append(\n",
    "            np.nanmean(X_raw_kept[i][t:t1,:], axis=0)\n",
    "            )\n",
    "        # X_new[i].append(np.nanmean(X_raw_kept[i][t:t1,:], axis=0))\n",
    "        t_new[i].append(int((tsraw[i][t1-1]+tsraw[i][t])/2))\n",
    "        t = t1\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get X_t, mask, etc\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "print('get X_t, mask, etc')\n",
    "X_t = np.empty([N], dtype=object)        # N * [t*d]\n",
    "X_t_mask = np.empty([N], dtype=object)   # N * [t*d]\n",
    "T_t = t_new                                 # N * [t]\n",
    "deltaT_t = np.empty([N], dtype=object)   # N * [t*d]\n",
    "for i in range(N):\n",
    "    if i % 20 == 0:\n",
    "        print('.',end='')\n",
    "        sys.stdout.flush()\n",
    "    X_t[i] = np.vstack(X_new[i])\n",
    "    X_t_mask[i] = 1-np.isnan(X_t[i]).astype('int8')\n",
    "    X_t[i][np.isnan(X_t[i])] = 0\n",
    "    deltaT_t[i] = np.zeros_like(X_t[i], dtype=int)\n",
    "    deltaT_t[i][0,:] = 0\n",
    "    for i_t in range(1, len(T_t[i])):\n",
    "        deltaT_t[i][i_t,:] = T_t[i][i_t] - T_t[i][i_t-1] + \\\n",
    "            (1-X_t_mask[i][i_t-1,:]) * deltaT_t[i][i_t-1,:]\n",
    "print('done!')\n",
    "del X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get labels\n",
      "# of class, subcat:\n"
     ]
    }
   ],
   "source": [
    "# extract subcat labels\n",
    "# for i_n, label_i in enumerate(label_icd9_all):\n",
    "#     for i_li, label_vec in enumerate(label_i):\n",
    "#         subcat = get_icd9_subcat_label(label_vct[2])\n",
    "#         label_i[i_li].append(subcat)\n",
    "#     label_icd9_all[i_n] = label_i\n",
    "        \n",
    "# get labels\n",
    "print('get labels')\n",
    "class_icd9_counts = np.bincount(y_icd90.5 * test_ratio or \\\n",
    "                                trva_percent < 0.5 + 0.5 * test_ratio:\n",
    "    np.concatenate(label_icd9_all)[:,3].astype(int))\n",
    "class_icd9_list = np.where(class_icd9_counts > 10)[0]\n",
    "class_icd9_list.sort()\n",
    "\n",
    "# class_icd9_subcat_counts = np.bincount(\n",
    "#     np.concatenate(label_icd9_all)[:,4].astype(int))\n",
    "# class_icd9_subcat_list = np.where(class_icd9_subcat_counts >= 200)[0]\n",
    "# class_icd9_subcat_list.sort()\n",
    "\n",
    "n_class_icd9 = class_icd9_list.shape[0]\n",
    "# n_class_icd9_subcat = class_icd9_subcat_list.shape[0]\n",
    "y_icd9 = np.zeros([N, n_class_icd9], dtype=int)\n",
    "# y_icd9_subcat = np.zeros([N, n_class_icd9_subcat], dtype=int)\n",
    "for i_n, label_i in enumerate(label_icd9_all):\n",
    "        for label_vec in label_i:\n",
    "            class_idx = np.array(\n",
    "                [cl == label_vec[3] for cl in class_icd9_list],\n",
    "                dtype=bool)\n",
    "            y_icd9[i_n][class_idx] = 1\n",
    "#             subcat_idx = np.array(\n",
    "#                 [cl == label_vec[4] for cl in class_icd9_subcat_list],\n",
    "#                 dtype=bool)\n",
    "#             y_icd9_subcat[i_n][subcat_idx] = 1\n",
    "\n",
    "y_mor = np.expand_dims(np.array(label_mor_all[:,4], dtype=int), axis=1)\n",
    "age_days = label_mor_all[:, 2]\n",
    "y_los = label_mor_all[:, 3]\n",
    "            \n",
    "# print('# of class, subcat:', n_class_icd9, n_class_icd9_subcat)\n",
    "print('# of class, subcat:')\n",
    "\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep-stats.npz'), \n",
    "         class_icd9_list=class_icd9_list, \n",
    "         class_icd9_counts=class_icd9_counts,\n",
    "#          class_icd9_subcat_list=class_icd9_subcat_list,\n",
    "#          class_icd9_subcat_counts=class_icd9_subcat_counts,\n",
    "         keep_val_idx_list=keep_val_idx_list, \n",
    "         ep_tdata_mean=ep_tdata_mean, ep_tdata_std=ep_tdata_std,\n",
    "         n_class_icd9=n_class_icd9, \n",
    "#          n_class_icd9_subcat=n_class_icd9_subcat,\n",
    "         N=N, val_mr=val_mr, idx_x=idx_x, age_days=age_days)\n",
    "\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep.npz'), \n",
    "         X_t=X_t,X_t_mask=X_t_mask,T_t=T_t,deltaT_t=deltaT_t,\n",
    "         y_icd9=y_icd9, y_mor=y_mor, adm_features_all=adm_features_all, adm_labels_all=adm_labels_all,y_los=y_los)\n",
    "# , y_icd9_subcat=y_icd9_subcat)\n",
    "\n",
    "del X_t, X_t_mask, deltaT_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate time series without sampling and imputation\n",
    "\n",
    "After this step, we get:\n",
    "- normed-ep-ratio.npz: data after averaging and before sampling. **For 17 processed features, we should use norm-ep-ratio.npz since it includes PaO2/FiO2 ratio**.\n",
    "    - ‘X_t’: temporal data. Shape: [number of admissions][number of timestamps, number of temporal features].\n",
    "    - ‘X_t_mask’: masks of temporal data. Shape: [number of admissions][number of timestamps, number of temporal features].\n",
    "    - ‘T_t’: timestamps of temporal data: num of seconds from current record to the icu admission time. Shape: [number of admissions][number of timestamps].\n",
    "    - ‘deltaT_t’: number of seconds from current record to the latest valid (not none) record before it. Shape: [number of admissions][number of timestamps].\n",
    "    - ‘y_icd9’: icd9 labels. Shape: [number of admissions, number of icd9 categories].\n",
    "    - ‘y_mor’: in-hospital mortality labels. Shape: [number of admissions].\n",
    "    - ‘adm_features_all’: non-temporal features of admissions, containing: age(days)/acquired immunodeficiency syndrome/hematologic malignancy/metastatic cancer/admission type. Shape: [number of admissions, number of non-temporal features=5].\n",
    "    - ‘adm_labels_all’: mortality labels of admissions, containing: in-hospital/1-day/2-day/3-day/30-day/1-year mortality. Shape: [number of admissions, number of mortality labels=6].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell calculates the PaO2/FiO2 ratio based on normed-ep.npz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-abf1c3e84c11>:25: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  xto_ratio[:, PAO2_VAR] = xto[:, PAO2_VAR] / xto[:, FIO2_VAR]\n",
      "<ipython-input-16-abf1c3e84c11>:25: RuntimeWarning: invalid value encountered in true_divide\n",
      "  xto_ratio[:, PAO2_VAR] = xto[:, PAO2_VAR] / xto[:, FIO2_VAR]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "ep_origin = np.load(os.path.join(processed_data_path, 'normed-ep.npz'), allow_pickle=True)\n",
    "# Here we merge pao2 and fio2 and get pf ratio\n",
    "X_t_ratio = []\n",
    "X_t_ratio_mask = []\n",
    "T_t_ratio = []\n",
    "deltaT_t_ratio = []\n",
    "X_t_origin, X_t_origin_mask, T_t_origin, deltaT_t_origin = ep_origin['X_t'], ep_origin['X_t_mask'], ep_origin['T_t'], ep_origin['deltaT_t']\n",
    "for t in range(X_t_origin.shape[0]):\n",
    "    if t % 20 == 0:\n",
    "        print('.', end='')\n",
    "    xto = X_t_origin[t]\n",
    "    xtom = X_t_origin_mask[t]\n",
    "    tto = T_t_origin[t]\n",
    "    dto = deltaT_t_origin[t]\n",
    "    ratio_shape = (xto.shape[0], xto.shape[1] - 1)\n",
    "    xto_ratio = np.full(ratio_shape, np.nan)\n",
    "    xtom_ratio = np.full(ratio_shape, np.nan)\n",
    "    tto_ratio = tto\n",
    "    dto_ratio = np.full(ratio_shape, np.nan)\n",
    "    # keep others\n",
    "    for itratio, it in zip([xto_ratio, xtom_ratio, dto_ratio],[xto, xtom, dto]):\n",
    "        itratio[:, :PAO2_VAR] = it[:, :PAO2_VAR]\n",
    "        itratio[:, FIO2_VAR:] = it[:, FIO2_VAR + 1:]\n",
    "    # fix the ratio part\n",
    "    xto_ratio[:, PAO2_VAR] = xto[:, PAO2_VAR] / xto[:, FIO2_VAR]\n",
    "    xto_ratio[np.isinf(xto_ratio)] = np.nan\n",
    "    xtom_ratio[:, PAO2_VAR] = np.logical_and(xtom[:, PAO2_VAR], xtom[:, FIO2_VAR])\n",
    "    dto_ratio[:, PAO2_VAR] = np.zeros_like(dto[:, PAO2_VAR])\n",
    "    for i_t in range(1, len(tto_ratio)):\n",
    "        dto_ratio[i_t,PAO2_VAR] = tto_ratio[i_t] - tto_ratio[i_t-1] + \\\n",
    "            (1-xtom_ratio[i_t-1,PAO2_VAR]) * dto_ratio[i_t-1,PAO2_VAR]\n",
    "    X_t_ratio.append(xto_ratio)\n",
    "    X_t_ratio_mask.append(xtom_ratio)\n",
    "    T_t_ratio.append(tto_ratio)\n",
    "    deltaT_t_ratio.append(dto_ratio)\n",
    "X_t_ratio = np.array(X_t_ratio, dtype=object)\n",
    "X_t_ratio_mask = np.array(X_t_ratio_mask, dtype=object)\n",
    "T_t_ratio = np.array(T_t_ratio, dtype=object)\n",
    "deltaT_t_ratio = np.array(deltaT_t_ratio, dtype=object)\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep-ratio.npz'), \n",
    "         X_t=X_t_ratio,X_t_mask=X_t_ratio_mask,T_t=T_t_ratio,deltaT_t=deltaT_t_ratio,\n",
    "         y_icd9=ep_origin['y_icd9'], y_mor=ep_origin['y_mor'], adm_features_all=ep_origin['adm_features_all'], adm_labels_all=ep_origin['adm_labels_all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and imputation\n",
    "\n",
    "After this step, we get the following files:\n",
    "- imputed-normed-ep_X_Y.npz: data after sampling and imputation. X (hours) is the length of interval of sampling and Y (hours) is the length of time series.\n",
    "    - ‘ep_data’: concatenated temporal data. Shape: [number of admissions, Y/X * number of temporal features].\n",
    "    - ‘ep_tdata’: temporal data. Shape: [number of admissions, Y/X, number of temporal features].\n",
    "    - ‘ep_data_masking’: concatenated masking of temporal data. Shape: [number of admissions, Y/X * number of temporal features].\n",
    "    - ‘ep_tdata_masking’: masking of temporal data. Shape: [number of admissions, Y/X, number of temporal features].\n",
    "    - ‘y_icd9’: icd9 labels. Shape: [number of admissions, number of icd9 categories].\n",
    "    - ‘y_mor’: in-hospital mortality labels. Shape: [number of admissions].\n",
    "    - ‘adm_features_all’: non-temporal features of admissions, containing: age(days)/acquired immunodeficiency syndrome/hematologic malignancy/metastatic cancer/admission type. Shape: [number of admissions, number of non-temporal features=5].\n",
    "    - ‘adm_labels_all’: mortality labels of admissions, containing: in-hospital/1-day/2-day/3-day/30-day/1-year mortality. Shape: [number of admissions, number of mortality labels=6].\n",
    "    - ‘y_los’: length of stay of admissions, unit is minute. Shape: [number of admissions].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get X_miss 2 24\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-bef43ca9ca45>:28: RuntimeWarning: Mean of empty slice\n",
      "  X_miss[i_n][i_t,:] = np.nanmean(X_raw_thist, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get X_imputed\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-bef43ca9ca45>:38: RuntimeWarning: Mean of empty slice\n",
      "  i_n_mean = np.nanmean(X_imputed[i_n], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get ep_tdata\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "calculating pao2/fio2 ratio...\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "imputing pao2/fio2 ratio...\n",
      "get X_withr_imputed\n",
      "......................................................"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-bef43ca9ca45>:105: RuntimeWarning: Mean of empty slice\n",
      "  i_n_mean = np.nanmean(ep_tdata_withr[i_n], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get X_miss 1 24\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get X_imputed\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get ep_tdata\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "calculating pao2/fio2 ratio...\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "imputing pao2/fio2 ratio...\n",
      "get X_withr_imputed\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "# get first N hours data\n",
    "# one data sample for one patient\n",
    "# hours_list = [(2, 24), (1, 24), (1, 48), (2, 48)]\n",
    "hours_list = [(2, HRS), (1, HRS)]\n",
    "for n_sample_hour, n_full_hour in hours_list:\n",
    "    print('get X_miss', n_sample_hour, n_full_hour)\n",
    "    #n_sample_hour = 2\n",
    "    #n_full_hour = HRS\n",
    "    n_time_step = int(n_full_hour / n_sample_hour)\n",
    "    # get X_miss first from X_raw_all_kept and tsraw, (sampled)\n",
    "    X_miss = np.empty([N], dtype = object)\n",
    "    T_miss = np.zeros([N], dtype = int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        T_miss[i_n] = math.ceil(\n",
    "            (tsraw[i_n][-1]-tsraw[i_n][0])*1.0/(60*60*n_sample_hour))\n",
    "        X_miss[i_n] = np.zeros([T_miss[i_n], n_temporal_var], dtype=float)\n",
    "        for i_t in range(T_miss[i_n]):\n",
    "            t_idx = np.logical_and(\n",
    "                (tsraw[i_n]-tsraw[i_n][0]) >= i_t*(60*60*n_sample_hour),\n",
    "                (tsraw[i_n]-tsraw[i_n][0]) <= (1+i_t) * (60*60*n_sample_hour))\n",
    "            X_raw_thist = X_raw_kept[i_n][t_idx, :]\n",
    "            # Here we do not normalize the data!!!\n",
    "#             X_miss[i_n][i_t,:] = \\\n",
    "#                 (np.nanmean(X_raw_thist, axis=0) - ep_tdata_mean) / ep_tdata_std\n",
    "            X_miss[i_n][i_t,:] = np.nanmean(X_raw_thist, axis=0)\n",
    "    print('done!')\n",
    "    # X_imputed: do forward/backward imputing from X_miss for lab events\n",
    "    #            do mean imputing for other events\n",
    "    print('get X_imputed')\n",
    "    X_imputed = deepcopy(X_miss)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        i_n_mean = np.nanmean(X_imputed[i_n], axis=0)\n",
    "        for i_t in range(1, T_miss[i_n]):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    if keep_val_idx_list[0][i_d] in lab_events_idx:\n",
    "                        X_imputed[i_n][i_t, i_d] = X_imputed[i_n][i_t-1, i_d]\n",
    "        for i_t in range(T_miss[i_n]-2, -1, -1):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    if keep_val_idx_list[0][i_d] in lab_events_idx:\n",
    "                        X_imputed[i_n][i_t, i_d] = X_imputed[i_n][i_t+1, i_d]\n",
    "        # X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "        # Here we use mean value of each feature in current time series to impute nans\n",
    "        for i_t in range(0, T_miss[i_n]):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    X_imputed[i_n][i_t, i_d] = i_n_mean[i_d]\n",
    "        # for values which are still none, just impute with 0\n",
    "#         X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "    print('done!')\n",
    "        \n",
    "    # get first # hours, for both data and masking\n",
    "    print('get ep_tdata')\n",
    "    ep_tdata = np.zeros([N, n_time_step, n_temporal_var], dtype=float)\n",
    "    ep_tdata_masking = np.zeros_like(ep_tdata, dtype=int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        xx_imp = X_imputed[i_n]\n",
    "        xx_mis = X_miss[i_n]\n",
    "        tt_min = min(n_time_step, len(xx_imp))\n",
    "        assert tt_min > 0\n",
    "        ep_tdata[i_n, :tt_min, :] = xx_imp[:tt_min, :]\n",
    "        ep_tdata[i_n, tt_min:, :] = ep_tdata[i_n, tt_min-1, :][None, :]\n",
    "        ep_tdata_masking[i_n, :tt_min, :] = \\\n",
    "            (~np.isnan(xx_mis[:tt_min, :])).astype(int)\n",
    "    print('done!')\n",
    "    \n",
    "    # After imputation, calc the pf ratio!!!\n",
    "    print('calculating pao2/fio2 ratio...')\n",
    "    ep_tdata_withr = np.zeros([N, n_time_step, n_temporal_var - 1], dtype=float)\n",
    "    ep_tdata_masking_withr = np.zeros_like(ep_tdata_withr, dtype=int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        pfratio = ep_tdata[i_n, :, PAO2_VAR] / ep_tdata[i_n, :, FIO2_VAR]\n",
    "        pfratio_masking = np.logical_and(ep_tdata_masking[i_n, :, PAO2_VAR] == 1,\n",
    "                                        ep_tdata_masking[i_n, :, FIO2_VAR] == 1).astype(int)\n",
    "        ep_tdata_withr[i_n, :, :PAO2_VAR] = ep_tdata[i_n, :, :PAO2_VAR]\n",
    "        ep_tdata_withr[i_n, :, PAO2_VAR] = pfratio\n",
    "        ep_tdata_withr[i_n, :, FIO2_VAR:] = ep_tdata[i_n, :, FIO2_VAR + 1:]\n",
    "        ep_tdata_masking_withr[i_n, :, :PAO2_VAR] = ep_tdata_masking[i_n, :, :PAO2_VAR]\n",
    "        ep_tdata_masking_withr[i_n, :, PAO2_VAR] = pfratio_masking\n",
    "        ep_tdata_masking_withr[i_n, :, FIO2_VAR:] = ep_tdata_masking[i_n, :, FIO2_VAR + 1:]\n",
    "    ep_tdata_withr[np.isinf(ep_tdata_withr)] = np.nan\n",
    "#     ep_tdata_masking_withr[np.isnan(ep_tdata_withr)] = 0\n",
    "    print('done!')\n",
    "    \n",
    "    # After calc ratio, impute the ratio!!!\n",
    "    print('imputing pao2/fio2 ratio...')\n",
    "    print('get X_withr_imputed')\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        i_n_mean = np.nanmean(ep_tdata_withr[i_n], axis=0)\n",
    "        tslen = ep_tdata_withr[i_n].shape[0]\n",
    "        for i_t in range(1, tslen):\n",
    "            for i_d in [PAO2_VAR]:\n",
    "                if np.isnan(ep_tdata_withr[i_n, i_t, i_d]):\n",
    "                    ep_tdata_withr[i_n, i_t, i_d] = ep_tdata_withr[i_n, i_t - 1, i_d]\n",
    "        for i_t in range(tslen-2, -1, -1):\n",
    "            for i_d in [PAO2_VAR]:\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    ep_tdata_withr[i_n, i_t, i_d] = ep_tdata_withr[i_n, i_t+1, i_d]\n",
    "        # X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "        # Here we use mean value of each feature in current time series to impute nans\n",
    "        for i_t in range(0, tslen):\n",
    "            for i_d in [PAO2_VAR]:\n",
    "                if np.isnan(ep_tdata_withr[i_n, i_t, i_d]):\n",
    "                    ep_tdata_withr[i_n, i_t, i_d] = i_n_mean[i_d]\n",
    "    # for values which are still none, just impute with 0\n",
    "#     ep_tdata_withr[np.isnan(ep_tdata_withr)] = 0\n",
    "    print('done!')\n",
    "    \n",
    "#     assert ep_tdata_withr[np.isnan(ep_tdata_withr)].shape == (0,)\n",
    "    \n",
    "    n_temporal_var_withr = n_temporal_var - 1\n",
    "    ep_data_withr = np.reshape(ep_tdata_withr, [N, n_time_step*n_temporal_var_withr])\n",
    "    ep_data_masking_withr = np.reshape(ep_tdata_masking_withr, [N, n_time_step*n_temporal_var_withr])\n",
    "    \n",
    "    np.savez(os.path.join(processed_data_path, \n",
    "                          'imputed-normed-ep' + '_' + str(n_sample_hour) + \\\n",
    "                          '_' + str(n_full_hour) + '.npz'), \n",
    "             ep_data = ep_data_withr, ep_tdata = ep_tdata_withr,\n",
    "             ep_data_masking = ep_data_masking_withr, \n",
    "             ep_tdata_masking = ep_tdata_masking_withr,\n",
    "             y_icd9 = y_icd9, y_mor = y_mor,adm_features_all=adm_features_all, adm_labels_all=adm_labels_all,y_los=y_los)\n",
    "#     , y_icd9_subcat=y_icd9_subcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15702, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_icd9.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making stratified folds and normalizing\n",
    "\n",
    "After this step, we get the following files:\n",
    "- 5-folds.npz: folds file containing indices of each fold. Folds are generated with stratified k-fold, which keeps the ratio of positive samples in training/test set. Therefore we generate a set of folds for each label. In each fold, we have 3 lists: indices of training/validation/test set.\n",
    "    - ‘folds_ep_icd9’: Sets of folds for icd9 classification tasks. Shape: [number of icd9 categories, 1(for compatibility), number of folds=5, 3(training/validation/test)].\n",
    "    - ‘folds_ep_icd9_multi’: For multi-classification of icd9, we only generate one set of folds based on the category of icd9 with fewest positive samples. Shape: [1, 1(for compatibility), number of folds=5, 3(training/validation/test)].\n",
    "    - ‘folds_ep_mor’: Sets of folds for mortality classification tasks. Shape: [number of  mortality kinds, 1(for compatibility), number of folds=5, 3(training/validation/test)].\n",
    "    - For length of stay regression task, we use the same folds with those used for in-hospital mortality task.\n",
    "- normed-ep-stdized.npz/normed-ep-ratio-stdized.npz/imputed-normed-ep_X_Y-stdized.npz: mean and standard error of each feature of normed-ep/normed-ep-ratio/imputed-normed-ep_X_Y. For each fold in 5-folds.npz file, we have the mean and standard error for temporal and non-temporal data. These parameters are calculated only with training data in order to prevent information leakage, and will be used for data normalization.\n",
    "    - ‘folds_ep_icd9’: shape: [number of icd9 categories, 1(for compatibility), number of folds=5, 2(temporal/non-temporal), 2(mean/standard error)].\n",
    "    - ‘folds_ep_icd9_multi’: shape: [1, 1(for compatibility), number of folds=5, 2(temporal/non-temporal), 2(mean/standard error)].\n",
    "    - ‘folds_ep_mor’: shape: [number of mortality kinds, 1(for compatibility), number of folds=5, 2(temporal/non-temporal), 2(mean/standard error)].\n",
    "    - For length of stay regression task, we use the same parameters with those used for in-hospital mortality task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make splits\n",
      "multi task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-7db4b34f1005>:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  foldsstat.append(np.array(stats))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish /media/data/mimic/hf_admdata_17f/24hrs/series/mv\n",
      "multi task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-7db4b34f1005>:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  foldsstat.append(np.array(stats))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish /media/data/mimic/hf_admdata_17f/24hrs/series/cv\n",
      "multi task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-7db4b34f1005>:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  foldsstat.append(np.array(stats))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish /media/data/mimic/hf_admdata_17f/24hrs/series\n",
      "multi task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-7db4b34f1005>:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  foldsstat.append(np.array(stats))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish /media/data/mimic/hf_admdata_17f/24hrs/series/mv\n",
      "multi task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-7db4b34f1005>:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  foldsstat.append(np.array(stats))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish /media/data/mimic/hf_admdata_17f/24hrs/series/cv\n",
      "multi task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-7db4b34f1005>:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  foldsstat.append(np.array(stats))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish /media/data/mimic/hf_admdata_17f/24hrs/series\n",
      "multi task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-7db4b34f1005>:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  foldsstat.append(np.array(stats))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish /media/data/mimic/hf_admdata_17f/24hrs/series/mv\n",
      "multi task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-7db4b34f1005>:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  foldsstat.append(np.array(stats))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish /media/data/mimic/hf_admdata_17f/24hrs/series/cv\n",
      "multi task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-7db4b34f1005>:94: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  foldsstat.append(np.array(stats))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish /media/data/mimic/hf_admdata_17f/24hrs/series\n"
     ]
    }
   ],
   "source": [
    "# imputed_data = np.load('../../Data/admdata_17f/24hrs_raw/series/imputed-normed-ep_1_24.npz')\n",
    "# y_icd9 = imputed_data['y_icd9']\n",
    "# adm_labels_all = imputed_data['adm_labels_all']\n",
    "\n",
    "print('make splits')\n",
    "# make 5-fold cv splits if file not exists\n",
    "def make_splits_on(y_mor, foldn):\n",
    "    folds_ep_mor = []\n",
    "    for i in range(1):\n",
    "        folds_ep_mor.append(make_splits(y_mor, foldn))\n",
    "    return folds_ep_mor\n",
    "\n",
    "def gen_folds_ids(foldn, fold_file_path, **kwargs):\n",
    "    # generate folds based on label sets\n",
    "    folds = {}\n",
    "    for labelname, (labelarray, is_multi_task) in kwargs.items():\n",
    "        assert len(labelarray.shape) > 1\n",
    "        folds[labelname] = []\n",
    "        if is_multi_task:\n",
    "            print(\"multi task\")\n",
    "            for ln in range(labelarray.shape[1]):\n",
    "                tempy = labelarray[:, ln]\n",
    "                try:\n",
    "                    lnfold = make_splits_on(tempy, foldn)\n",
    "                except:\n",
    "                    print('pass {0} {1}'.format(labelname, ln))\n",
    "                    lnfold = None\n",
    "                folds[labelname].append(lnfold)\n",
    "        else:\n",
    "            print(\"not multi task\")\n",
    "            folds[labelname].append(make_splits_on(labelarray, foldn))\n",
    "    np.savez(fold_file_path, **folds)\n",
    "    return folds\n",
    "\n",
    "def get_standardize_stats_for_training(ep_tdata, ep_tdata_masking, adm_features_all, training_ids):\n",
    "    trainset = ep_tdata[training_ids]\n",
    "    trainset_masking = ep_tdata_masking[training_ids]\n",
    "    train_admfeatures = adm_features_all[training_ids]\n",
    "    id_num = trainset.shape[0]\n",
    "    dim = trainset.shape[2]\n",
    "    stats = np.empty((dim, 2)) * np.nan\n",
    "    for d in range(dim):\n",
    "        dim_values = trainset[:,:,d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        stats[d,:] = np.array([dim_mean, dim_std])\n",
    "    nsdim = adm_features_all.shape[1]\n",
    "    nsstats = np.empty((nsdim, 2)) * np.nan\n",
    "    for d in range(nsdim):\n",
    "        dim_values = train_admfeatures[:, d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        nsstats[d,:] = np.array([dim_mean, dim_std])\n",
    "    return stats, nsstats\n",
    "\n",
    "def get_standardize_stats_for_training_missing(ep_tdata, ep_tdata_masking, adm_features_all, training_ids):\n",
    "    trainset = np.concatenate(ep_tdata[training_ids])\n",
    "    trainset_masking = np.concatenate(ep_tdata_masking[training_ids])\n",
    "    train_admfeatures = adm_features_all[training_ids]\n",
    "    id_num = trainset.shape[0]\n",
    "    dim = trainset.shape[1]\n",
    "    stats = np.empty((dim, 2)) * np.nan\n",
    "    for d in range(dim):\n",
    "        dim_masking = trainset_masking[:,d].flatten()\n",
    "        dim_values = trainset[:,d].flatten()[np.where(dim_masking==1)]\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        stats[d,:] = np.array([dim_mean, dim_std])\n",
    "    nsdim = adm_features_all.shape[1]\n",
    "    nsstats = np.empty((nsdim, 2)) * np.nan\n",
    "    for d in range(nsdim):\n",
    "        dim_values = train_admfeatures[:, d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        nsstats[d,:] = np.array([dim_mean, dim_std])\n",
    "    return stats, nsstats\n",
    "\n",
    "def get_standardize_stats_for_folds(folds, stdfunc, ep_tdata, ep_tdata_masking, adm_features_all):\n",
    "    statsdict = {}\n",
    "    for key, value in folds.items():\n",
    "        statsdict[key] = []\n",
    "        for folds_ids in value:\n",
    "            foldsstat = []\n",
    "            for folds_ep_mor in folds_ids:\n",
    "                foldsn = folds_ep_mor.shape[0]\n",
    "                stats = []\n",
    "                ep_tdata_stdized_list = []\n",
    "                for foldn in range(foldsn):\n",
    "                    training_ids = folds_ep_mor[foldn,0]\n",
    "                    stat, nsstat = stdfunc(ep_tdata=ep_tdata, ep_tdata_masking=ep_tdata_masking, adm_features_all=adm_features_all, training_ids=training_ids)\n",
    "                    fstat = [stat[:, 0], stat[:, 1]]\n",
    "                    fnsstat = [nsstat[:, 0], nsstat[:, 1]]\n",
    "                    stats.append([fstat, fnsstat])\n",
    "                foldsstat.append(np.array(stats))\n",
    "            statsdict[key].append(foldsstat)\n",
    "    return statsdict\n",
    "\n",
    "def split_dataset(datasetfilename, ep_tdata_attr, ep_tdata_masking_attr, ep_adm_features_all_attr, \n",
    "                  aidwhere, statfunc, foldn, fold_filedir, **kwargs):\n",
    "    dataset = np.load(os.path.join(processed_data_path, datasetfilename + '.npz'), allow_pickle=True)\n",
    "    subdataset = {}\n",
    "    for key, value in dataset.items():\n",
    "        subdataset[key] = value[aidwhere]\n",
    "    sub_tdata = subdataset[ep_tdata_attr]\n",
    "    sub_masking = subdataset[ep_tdata_masking_attr]\n",
    "    sub_label_all = subdataset[ep_adm_features_all_attr]\n",
    "    sublabelset = {}\n",
    "    for key, (value, is_multi_task) in kwargs.items():\n",
    "        sublabelset[key] = (value[aidwhere], is_multi_task)\n",
    "    if not os.path.exists(fold_filedir):\n",
    "        os.makedirs(fold_filedir)\n",
    "    fold_file_path = os.path.join(fold_filedir, '%d-folds.npz' % foldn)\n",
    "    folds = gen_folds_ids(foldn=foldn, fold_file_path=fold_file_path, **sublabelset)\n",
    "    statsdict = get_standardize_stats_for_folds(folds, statfunc, ep_tdata=sub_tdata, ep_tdata_masking=sub_masking, adm_features_all=sub_label_all)\n",
    "    np.savez(os.path.join(fold_filedir, datasetfilename+'-stdized.npz'), **statsdict)\n",
    "#     if not os.path.exists(os.path.join(fold_filedir, datasetfilename+'.npz')):\n",
    "    np.savez(os.path.join(fold_filedir, datasetfilename+'.npz'), **subdataset)\n",
    "    print('finish', fold_filedir)\n",
    "\n",
    "from utils import getConnection\n",
    "\n",
    "# select ids in carevue\n",
    "sql = 'select distinct hadm_id from mimiciii.icustays where dbsource = \\'metavision\\' '\n",
    "sql += 'UNION select distinct hadm_id from mimiciii.transfers where dbsource = \\'metavision\\''\n",
    "conn = getConnection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(sql)\n",
    "res = cur.fetchall()\n",
    "mvaids = sorted([r[0] for r in res])\n",
    "mvaidset = set(mvaids)\n",
    "\n",
    "MVDIR = os.path.join(processed_data_path, 'mv')\n",
    "CVDIR = os.path.join(processed_data_path, 'cv')\n",
    "ALLDIR = processed_data_path\n",
    "data_all = np.load(os.path.join(working_path, 'DB_merged_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "allaids = np.array([t[0][-1] for t in data_all])\n",
    "mvwhere = np.array([aid in mvaidset for aid in allaids])\n",
    "cvwhere = ~mvwhere\n",
    "allwhere = np.logical_or(mvwhere, cvwhere)\n",
    "assert np.alltrue(allwhere)\n",
    "\n",
    "file_list = ['imputed-normed-ep_1_%d'%HRS, 'imputed-normed-ep_2_%d'%HRS]\n",
    "for filename in file_list:\n",
    "    for ids, dirname in zip([mvwhere, cvwhere, allwhere], [MVDIR, CVDIR, ALLDIR]):\n",
    "        split_dataset(\n",
    "            datasetfilename=filename,\n",
    "            ep_tdata_attr='ep_tdata',\n",
    "            ep_tdata_masking_attr='ep_tdata_masking',\n",
    "            ep_adm_features_all_attr='adm_features_all',\n",
    "            aidwhere=ids,\n",
    "            statfunc=get_standardize_stats_for_training,\n",
    "            foldn=5,\n",
    "            fold_filedir=dirname,\n",
    "#             folds_ep_icd9=(y_icd9, True),\n",
    "#             folds_ep_icd9_multi=(y_icd9, False),\n",
    "            folds_ep_mor=(adm_labels_all, True)\n",
    "        )\n",
    "        \n",
    "ep_datafilename = 'normed-ep-ratio'\n",
    "for ids, dirname in zip([mvwhere, cvwhere, allwhere], [MVDIR, CVDIR, ALLDIR]):\n",
    "    split_dataset(\n",
    "        datasetfilename=ep_datafilename,\n",
    "        ep_tdata_attr='X_t',\n",
    "        ep_tdata_masking_attr='X_t_mask',\n",
    "        ep_adm_features_all_attr='adm_features_all',\n",
    "        aidwhere=ids,\n",
    "        statfunc=get_standardize_stats_for_training_missing,\n",
    "        foldn=5,\n",
    "        fold_filedir=dirname,\n",
    "#         folds_ep_icd9=(y_icd9, True),\n",
    "#         folds_ep_icd9_multi=(y_icd9, False),\n",
    "        folds_ep_mor=(adm_labels_all, True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.45  4.45  4.45  4.45  4.45  4.45  4.45  4.45  4.45  4.45  4.45  4.45\n",
      " 4.45  4.45  4.45  4.45  4.45  4.45  3.425 3.425 3.425 3.425 3.425 3.425]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAASCklEQVR4nO3dfYxldX3H8c9n5t7ZuQM7d6o7Gsqg01pMSoguOCEmmEJBDAW7tvUhkJDQxHT9w7a0kBLpAxVM/6C2SNLYputDIFJrqba6QU1LYDfVRsBZQRSwlti1Qik7KrMPXfZxvv3jntkdxxnmPpxzfufe+34lk733nt/e+eZw89kfv3t+3+OIEACg/42kLgAAkA8CHQAGBIEOAAOCQAeAAUGgA8CAqKX6xVu2bInZ2dlUvx4A+tKePXt+GBHTax1LFuizs7Oan59P9esBoC/Z/v56x1hyAYABQaADwIAg0AFgQBDoADAgCHQAGBAEOgAMCAIdAAZEsuvQu/X1vT/WV767kLoMYKjNbjlDv3HhTOoysErfBfo3vv+i/mrXM6nLAIbW8i0Urn7DWdpUG01bDH5C3wX6+y55nd53yetSlwEMrU99ba/+5AtPav9Lx/WqzQR6lbCGDqAjk426JOnAS8cTV4LVCHQAHWlmgb54mECvGgIdQEeWA30/M/TKIdABdIRAry4CHUBHCPTqajvQbY/afsz2/S8z5p22w/ZcPuUBqBoCvbo6maHfIOnp9Q7a3pyNeaTXogBUV210RGduqhHoFdRWoNuekXS1pI+/zLAPSbpD0pEc6gJQYc1GnUCvoHZn6HdJulnS0loHbV8o6ZyI+OLLvYnt7bbnbc8vLLB9H+hXk40616FX0IaBbvvtkvZFxJ51jo9IulPSTRu9V0TsiIi5iJibnl7zHqcA+kCzUeM69ApqZ4Z+saRttvdK+oyky2zfu+L4ZknnS9qdjXmzpJ18MQoMLpZcqmnDQI+IWyJiJiJmJV0j6aGIuG7F8f0RsSUiZrMxD0vaFhHzRRUNIC0CvZq6vg7d9u22t+VZDID+MDUxRqBXUEfdFiNit6Td2eNb1xlzaa9FAai2ZqOuoyeWdOT4SY3X6bhYFewUBdAxOi5WE4EOoGPsFq0mAh1Ax0610CXQK4VAB9CxUzN0rkWvFAIdQMdYcqkmAh1Ax6YI9Eoi0AF0bJJAryQCHUDHRkeszbTQrRwCHUBX6LhYPQQ6gK40G3UuW6wYAh1AV2jQVT0EOoCuEOjVQ6AD6MrUBIFeNQQ6gK4wQ68eAh1AVyYbdR3LWuiiGgh0AF1h+3/1EOgAukKgVw+BDqArp1ro0nGxMgh0AF1hhl49BDqArkxNEOhVQ6AD6Aoz9Ooh0AF0ZfM4gV41BDqAroyOWJvHa3RcrBACHUDX2C1aLQQ6gK41G3UtHj6WugxkCHQAXWOGXi0EOoCuEejVQqAD6Fqrhe6J1GUgQ6AD6NryfUUjInUpUAeBbnvU9mO271/j2I22n7L9hO0Hbb823zIBVFGzUdexk0s6cnwpdSlQZzP0GyQ9vc6xxyTNRcQbJH1W0p/3WhiA6mO3aLW0Fei2ZyRdLenjax2PiF0RcTh7+rCkmXzKA1BlBHq1tDtDv0vSzZLa+f+q90r68loHbG+3PW97fmFhoc1fDaCqTrfQ5Vr0Ktgw0G2/XdK+iNjTxtjrJM1J+vBaxyNiR0TMRcTc9PR0x8UCqBZm6NVSa2PMxZK22b5K0rikSdv3RsR1KwfZfqukP5J0SUQczb9UAFUz1RiTRKBXxYYz9Ii4JSJmImJW0jWSHlojzC+Q9LeStkXEvkIqBVA5zNCrpevr0G3fbntb9vTDks6U9I+2H7e9M5fqAFTa5vGabNFxsSLaWXI5JSJ2S9qdPb51xetvzbUqAH1hZMTavKnGDL0i2CkKoCfNCfq5VAWBDqAnzUZdiwR6JRDoAHpCx8XqINAB9GSqMUagVwSBDqAnyx0XkR6BDqAny0sutNBNj0AH0JNmo67jJ0MvHT+ZupShR6AD6Am7RauDQAfQEwK9Ogh0AD053UKXQE+NQAfQk6kJZuhVQaAD6AlLLtVBoAPoyWQW6FyLnh6BDqAnmze1WugyQ0+PQAfQk5ERa3Kcfi5VQKAD6BkNuqqBQAfQs2ajzmWLFUCgA+jZFDe5qAQCHUDP6LhYDQQ6gJ6xhl4NBDqAntFCtxoIdAA9azbqOrEUOnyMFropEegAesb2/2og0AH0jECvBgIdQM+maKFbCQQ6gJ5NMkOvBAIdQM+adFysBAIdQM+a3OSiEgh0AD07c6ymEVroJkegA+jZyIg1yW7R5NoOdNujth+zff8axzbZ/gfbz9h+xPZsrlUCqDy2/6fXyQz9BklPr3PsvZJejIhfkPQRSXf0WhiA/tJs1LVIoCfVVqDbnpF0taSPrzPkHZLuyR5/VtLltt17eQD6BTP09Nqdod8l6WZJS+scP1vSDyQpIk5I2i/plasH2d5ue972/MLCQufVAqisJi10k9sw0G2/XdK+iNjT6y+LiB0RMRcRc9PT072+HYAKYYaeXjsz9IslbbO9V9JnJF1m+95VY56TdI4k2a5Jakr6UY51Aqg4Wuimt2GgR8QtETETEbOSrpH0UERct2rYTknXZ4/flY3hvyowRJqNuk4uhf6PFrrJdH0duu3bbW/Lnn5C0ittPyPpRkkfyKM4AP2Djovp1ToZHBG7Je3OHt+64vUjkt6dZ2EA+kvzVMfFYzp7qpG4muHETlEAuaCfS3oEOoBc0HExPQIdQC5YQ0+PQAeQCwI9PQIdQC7O3FTT6IgJ9IQIdAC5sK3J8RqBnhCBDiA3rd2iJ1KXMbQIdAC5aU6MafHwsdRlDC0CHUBu6LiYFoEOIDd0XEyLQAeQm2aDL0VTItAB5KbZqOvAkRO00E2EQAeQm+UWuoeOcqVLCgQ6gNywWzQtAh1AbpqNMUnS4mECPQUCHUBu6LiYFoEOIDcsuaRFoAPIDTe5SItAB5AbZuhpEegAcnPG2CgtdBMi0AHkxjbb/xMi0AHkaopAT4ZAB5CrSQI9GQIdQK5YckmHQAeQKwI9HQIdQK4I9HQIdAC5Wr5r0dISLXTLRqADyFWzUddSSIeO0UK3bAQ6gFyd2v5Px8XSbRjotsdtP2r7m7aftH3bGmNeY3uX7cdsP2H7qmLKBVB1bP9Pp50Z+lFJl0XEGyVtlXSl7TevGvPHku6LiAskXSPpr3OtEkDfINDTqW00IFo3BzyUPa1nP6u/7QhJk9njpqT/yatAAP2FQE+nrTV026O2H5e0T9IDEfHIqiEflHSd7WclfUnS7+RZJID+QaCn01agR8TJiNgqaUbSRbbPXzXkWkl3R8SMpKskfcr2T7237e22523PLyws9Fg6gCoi0NPp6CqXiFiUtEvSlasOvVfSfdmYr0kal7Rljb+/IyLmImJuenq6q4IBVNvE2KhqtNBNop2rXKZtT2WPG5KukPSdVcP+W9Ll2ZhfVCvQmYIDQ4gWuuls+KWopLMk3WN7VK1/AO6LiPtt3y5pPiJ2SrpJ0sds/75aX5D+ZvZlKoAh1Jwg0FNo5yqXJyRdsMbrt654/JSki/MtDUC/ajbqbCxKgJ2iAHLHkksaBDqA3BHoaRDoAHJHoKdBoAPIXbNR14EjtNAtG4EOIHfNRl0R0sGjtNAtE4EOIHfLu0UPsOxSKgIdQO6WA32RSxdLRaADyB39XNIg0AHk7tRdiwj0UhHoAHLHDD0NAh1A7gj0NAh0ALlr1EdVH6WFbtkIdAC5a7XQHSPQS0agAyhEs1HT/peOpS5jqBDoAApBP5fyEegACkGgl49AB1AIAr18BDqAQnDXovIR6AAK0WzUdfDoCVrolohAB1CI5sRYq4XuEVroloVAB1AIdouWj0AHUIhTLXS5Fr00BDqAQjBDLx+BDqAQBHr5CHQAhSDQy0egAygEgV4+Ah1AIcbrIxqrjRDoJSLQARSi1UK3rgMEemkIdACFaTbqWmT7f2kIdACFoUFXuTYMdNvjth+1/U3bT9q+bZ1x77H9VDbm0/mXCqDfEOjlqrUx5qikyyLikO26pK/a/nJEPLw8wPa5km6RdHFEvGj7VQXVC6CPNBt1ffeFg6nLGBobBnpEhKRD2dN69rO6fdpvSfpoRLyY/Z19eRYJoD8xQy9XW2votkdtPy5pn6QHIuKRVUNeL+n1tv/d9sO2r1znfbbbnrc9v7Cw0FPhAKqv2ajr4JETOkkL3VK0FegRcTIitkqakXSR7fNXDalJOlfSpZKulfQx21NrvM+OiJiLiLnp6ele6gbQB5Y3Fx08wiy9DB1d5RIRi5J2SVo9A39W0s6IOB4R/yXpu2oFPIAhxm7RcrVzlcv08mzbdkPSFZK+s2rY59Wancv2FrWWYL6XY50A+tCpFrpci16Kdq5yOUvSPbZH1foH4L6IuN/27ZLmI2KnpH+R9DbbT0k6KekPIuJHhVUNoC80J5ihl6mdq1yekHTBGq/fuuJxSLox+wEASSy5lI2dogAKQ6CXi0AHUBgCvVwEOoDCjNdHtak2QsfFkhDoAArFbtHyEOgACkUL3fIQ6AAKxQy9PAQ6gEIR6OUh0AEUikAvD4EOoFCT3Fe0NAQ6gEJNTdR18CgtdMtAoAMo1PLmImbpxSPQARSK3aLlIdABFOpUC10CvXAEOoBCMUMvD4EOoFAEenkIdACFItDLQ6ADKNQkV7mUhkAHUKjx+qjG6yPM0EtAoAMoXLNR1346LhaOQAdQuGajrsWXjqUuY+AR6AAKR4OuchDoAArXCvQTqcsYeAQ6gMLRcbEcBDqAwk01xlhyKQGBDqBwzUZdh46e0ImTS6lLGWgEOoDCNRs1SdKBI6yjF4lAB1C45gTb/8tQS10AgMG33M/l+k8+qk015pG/e/m5+tU3/mzu70ugAyjcm177Cr3rTTM6fIwlF+n0P3B5I9ABFK7ZqOsv3v3G1GUMvA3/38f2uO1HbX/T9pO2b3uZse+0Hbbn8i0TALCRdmboRyVdFhGHbNclfdX2lyPi4ZWDbG+WdIOkRwqoEwCwgQ1n6NFyKHtaz35ijaEfknSHpCP5lQcAaFdbXzfbHrX9uKR9kh6IiEdWHb9Q0jkR8cUN3me77Xnb8wsLC93WDABYQ1uBHhEnI2KrpBlJF9k+f/mY7RFJd0q6qY332RERcxExNz093WXJAIC1dHRBaEQsStol6coVL2+WdL6k3bb3SnqzpJ18MQoA5WrnKpdp21PZ44akKyR9Z/l4ROyPiC0RMRsRs5IelrQtIuaLKRkAsJZ2ZuhnSdpl+wlJX1drDf1+27fb3lZseQCAdjlirQtWSvjF9oKk73f517dI+mGO5fQrzsNpnIsWzkPLIJ+H10bEml9CJgv0Xtiej4ihX6PnPJzGuWjhPLQM63mgSw4ADAgCHQAGRL8G+o7UBVQE5+E0zkUL56FlKM9DX66hAwB+Wr/O0AEAqxDoADAg+i7QbV9p+z9sP2P7A6nrScX2Xtvfsv247aHZlWv7k7b32f72itdeYfsB2/+Z/fkzKWssyzrn4oO2n8s+F4/bvipljUWzfY7tXbafyu7XcEP2+lB+Jvoq0G2PSvqopF+RdJ6ka22fl7aqpH45IrYO2fW2d+snewlJ0gckPRgR50p6MHs+DO7WT58LSfpI9rnYGhFfKrmmsp2QdFNEnKdWH6n3Z5kwlJ+Jvgp0SRdJeiYivhcRxyR9RtI7EteEEkXEv0n68aqX3yHpnuzxPZJ+rcyaUlnnXAyViHg+Ir6RPT4o6WlJZ2tIPxP9FuhnS/rBiufPZq8No5D0r7b32N6eupjEXh0Rz2eP/1fSq1MWUwG/bfuJbElmKJYaJMn2rKQL1Lpr2lB+Jvot0HHaWyLiQrWWn95v+5dSF1QF0boOd5ivxf0bSa+TtFXS85L+Mmk1JbF9pqTPSfq9iDiw8tgwfSb6LdCfk3TOiucz2WtDJyKey/7cJ+mf1VqOGlYv2D5LkrI/9yWuJ5mIeCG7Ic2SpI9pCD4X2b2OPyfp7yLin7KXh/Iz0W+B/nVJ59r+Odtjkq6RtDNxTaWzfUZ2U27ZPkPS2yR9++X/1kDbKen67PH1kr6QsJaklkMs8+sa8M+FbUv6hKSnI+LOFYeG8jPRdztFs8uw7pI0KumTEfFnaSsqn+2fV2tWLkk1SZ8elvNg++8lXapWe9QXJP2ppM9Luk/Sa9RqyfyeiBj4LwvXOReXqrXcEpL2SnrfirXkgWP7LZK+Iulbkpayl/9QrXX04ftM9FugAwDW1m9LLgCAdRDoADAgCHQAGBAEOgAMCAIdAAYEgQ4AA4JAB4AB8f/qXf2W9W1HlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check some plot\n",
    "k = 4\n",
    "\n",
    "# pao2 / fio2\n",
    "checkx = np.load(os.path.join(processed_data_path, 'imputed-normed-ep_1_%d.npz'%HRS), allow_pickle=True)['ep_tdata']\n",
    "checkidx = np.random.randint(checkx.shape[0])\n",
    "heart_rate = checkx[checkidx, :, k]\n",
    "print(heart_rate)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "plt.plot(heart_rate)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
