{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import psycopg2\n",
    "import datetime\n",
    "import sys\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import re\n",
    "import traceback\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "from utils import getConnection\n",
    "from utils import parseUnitsMap\n",
    "from utils import parseNum\n",
    "from utils import sparsify\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HRS = 24\n",
    "HRS = 48\n",
    "TARGETDIR = '/media/data/mimic/hf_admdata_17f/'\n",
    "HRDIR = os.path.join(TARGETDIR, '%dhrs_raw' % HRS)\n",
    "# HRDIR = os.path.join(TARGETDIR, '%dhrs' % HRS)\n",
    "RESDIR = os.path.join(HRDIR, 'non_series')\n",
    "SERIALDIR = os.path.join(HRDIR, 'series')\n",
    "\n",
    "if not os.path.exists(RESDIR):\n",
    "    os.makedirs(RESDIR)\n",
    "\n",
    "hrs_mean = np.load(os.path.join(RESDIR, 'tsmean_%dhrs.npz' % HRS), allow_pickle=True)\n",
    "hrs_mean_array = hrs_mean['hrs_mean_array']\n",
    "hrs_mean_labels = hrs_mean['hrs_mean_labels']\n",
    "\n",
    "INPUTFILEPATH = os.path.join(RESDIR, 'input.csv')\n",
    "ress = hrs_mean_array\n",
    "with open(INPUTFILEPATH, 'w') as f:\n",
    "    for res in ress:\n",
    "        f.write(','.join(list(map(lambda x: str(x) if x is not None else '', res))) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31912"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels\n",
    "adm_labels_all = np.load(os.path.join(HRDIR, 'ADM_LABELS_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "with open(os.path.join(RESDIR, 'output.csv'), 'w') as f:\n",
    "    for res in adm_labels_all:\n",
    "        f.write(','.join(list(map(str, res))) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31912\n"
     ]
    }
   ],
   "source": [
    "sql = 'select distinct hadm_id from mimiciii.icustays where dbsource = \\'metavision\\' '\n",
    "sql += 'UNION select distinct hadm_id from mimiciii.transfers where dbsource = \\'metavision\\''\n",
    "conn = getConnection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(sql)\n",
    "res = cur.fetchall()\n",
    "\n",
    "admission_ids = []\n",
    "for r in res:\n",
    "    admission_ids.append(r[0]) \n",
    "mv_admset = set(admission_ids)\n",
    "\n",
    "data_all = np.load(os.path.join(HRDIR, 'DB_merged_%dhrs.npy' % HRS), allow_pickle=True).tolist()\n",
    "valid_aids = [t[0][-1] for t in data_all]\n",
    "print(len(valid_aids))\n",
    "mv_flag = np.array([valid_aid in mv_admset for valid_aid in valid_aids])\n",
    "np.save(os.path.join(RESDIR, 'mv_flag.npy'), mv_flag)\n",
    "\n",
    "# input mv\n",
    "inputarray = np.genfromtxt(os.path.join(RESDIR, 'input.csv'), delimiter=',')[mv_flag]\n",
    "# output mv\n",
    "outputlabels = np.genfromtxt(os.path.join(RESDIR, 'output.csv'), delimiter=',')[mv_flag].astype(int)\n",
    "# save!\n",
    "np.savetxt(os.path.join(RESDIR, 'input_mv.csv'), inputarray, delimiter=',')\n",
    "np.savetxt(os.path.join(RESDIR, 'output_mv.csv'), outputlabels, delimiter=',')\n",
    "# input cv\n",
    "inputarray = np.genfromtxt(os.path.join(RESDIR, 'input.csv'), delimiter=',')[~mv_flag]\n",
    "# output cv\n",
    "outputlabels = np.genfromtxt(os.path.join(RESDIR, 'output.csv'), delimiter=',')[~mv_flag].astype(int)\n",
    "# save!\n",
    "np.savetxt(os.path.join(RESDIR, 'input_cv.csv'), inputarray, delimiter=',')\n",
    "np.savetxt(os.path.join(RESDIR, 'output_cv.csv'), outputlabels, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_0_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_1_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_2_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_3_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_4_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_0_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_1_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_2_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_3_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_4_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_0_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_1_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_2_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_3_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_4_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_0_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_1_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_2_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_3_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_4_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_0_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_1_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_2_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_3_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_4_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_0_5.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_1_5.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_2_5.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_3_5.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/input_4_5.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_0_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_1_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_2_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_3_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_4_0.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_0_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_1_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_2_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_3_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_4_1.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_0_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_1_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_2_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_3_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_4_2.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_0_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_1_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_2_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_3_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_4_3.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_0_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_1_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_2_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_3_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_4_4.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_0_5.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_1_5.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_2_5.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_3_5.csv\n",
      "../../Data/admdata_17f/48hrs_raw/non_series/folds/cv/input_4_5.csv\n"
     ]
    }
   ],
   "source": [
    "def gen_file_for_r(FOLDSPATH, FOLDSOUTPATH, RESDIR, inputfilename, outputfilename):\n",
    "    if not os.path.exists(FOLDSOUTPATH):\n",
    "        os.makedirs(FOLDSOUTPATH)\n",
    "    inputarray = np.genfromtxt(os.path.join(RESDIR, inputfilename), delimiter=',')\n",
    "    outputarray = np.genfromtxt(os.path.join(RESDIR, outputfilename), delimiter=',')\n",
    "    for t in range(len(adm_labels_all[0])):\n",
    "        folds = np.load(os.path.join(FOLDSPATH, '5-folds.npz'), allow_pickle=True)['folds_ep_mor'][t][0]\n",
    "        for fi, f in enumerate(folds):\n",
    "            train, valid, test = f[0], f[1], f[2]\n",
    "            train = np.concatenate((train, valid))\n",
    "            Xtrain = inputarray[train, :]\n",
    "            train_mean = np.nanmean(Xtrain, axis=0)\n",
    "            train_std = np.nanstd(Xtrain, axis=0)\n",
    "            newinput = np.copy(inputarray)\n",
    "            for l in range(newinput.shape[0]):\n",
    "                newinput[l,:] = (newinput[l,:] - train_mean) / train_std\n",
    "            newinput[np.isinf(newinput)] = 0\n",
    "            newinput[np.isnan(newinput)] = 0\n",
    "            np.savetxt(os.path.join(FOLDSOUTPATH, 'input_train_%d_%d.csv' % (fi, t)), newinput[train], delimiter=',')\n",
    "            np.savetxt(os.path.join(FOLDSOUTPATH, 'output_train_%d_%d.csv' % (fi, t)), outputarray[train], delimiter=',')\n",
    "            np.savetxt(os.path.join(FOLDSOUTPATH, 'input_test_%d_%d.csv' % (fi, t)), newinput[test], delimiter=',')\n",
    "            np.savetxt(os.path.join(FOLDSOUTPATH, 'output_test_%d_%d.csv' % (fi, t)), outputarray[test], delimiter=',')\n",
    "            print(os.path.join(FOLDSOUTPATH, 'input_%d_%d.csv' % (fi, t)))\n",
    "            \n",
    "gen_file_for_r(\n",
    "    SERIALDIR,\n",
    "    os.path.join(RESDIR, 'folds'),\n",
    "    RESDIR,\n",
    "    'input.csv',\n",
    "    'output.csv'\n",
    ")\n",
    "\n",
    "gen_file_for_r(\n",
    "    os.path.join(SERIALDIR, 'cv'),\n",
    "    os.path.join(RESDIR, 'folds', 'cv'),\n",
    "    RESDIR,\n",
    "    'input_cv.csv',\n",
    "    'output_cv.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
