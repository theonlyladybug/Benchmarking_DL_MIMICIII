{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "# from sklearn.cross_validation import StratifiedShuffleSplit, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sys.path.append(\"..\")\n",
    "# from dataprocessing.util import make_splits\n",
    "\n",
    "def try_making_splits(y, nfold, test_ratio=None):\n",
    "    '''\n",
    "    y: n*n_class\n",
    "        tries to find n splits, where:\n",
    "        size of (train, valid, test) is (nfold-2, 1, 1)\n",
    "        # of samples for one class is (>=1/2, >=0.5*ratio, >=0.5*ratio)\n",
    "    '''\n",
    "    idx_list = np.empty([nfold, 3], dtype=object)\n",
    "    if test_ratio is None:\n",
    "        test_ratio = 1.0 / nfold\n",
    "    n_samples, n_classes = y.shape\n",
    "    i_class_least = np.argmin(np.sum(y, axis=0))\n",
    "    i_trial = 0\n",
    "    print('\\nnew try: ', i_trial,)\n",
    "    cnt = 0\n",
    "    while i_trial < nfold:\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print('{} trials'.format(cnt))\n",
    "        success_flag = True\n",
    "        ss = StratifiedShuffleSplit(n_splits=1,\n",
    "                                    test_size=test_ratio)\n",
    "        for idx_trva, idx_te in ss.split(np.zeros(len(y[:, i_class_least])), y[:, i_class_least]):  # length is only 1 !\n",
    "            for i_class in range(n_classes):\n",
    "                te_percent = 1.0 * np.sum(y[idx_te, i_class]) / np.sum(y[:, i_class])\n",
    "                trva_percent = 1.0 * np.sum(y[idx_trva, i_class]) / np.sum(y[:, i_class])\n",
    "                if te_percent < 0.5 * test_ratio or \\\n",
    "                                trva_percent < 0.5 + 0.5 * test_ratio:\n",
    "                    success_flag = False\n",
    "                    break\n",
    "            if not success_flag:\n",
    "                break\n",
    "        if not success_flag:\n",
    "            continue\n",
    "        cnt2 = 0\n",
    "        while cnt2 < 1000:\n",
    "            cnt2 += 1\n",
    "            success_flag = True\n",
    "            ss2 = StratifiedShuffleSplit(n_splits=1,\n",
    "                                         test_size=test_ratio * n_samples / len(idx_trva))\n",
    "            for idx_tr_ss2, idx_va_ss2 in ss2.split(np.zeros(len(idx_trva)), y[idx_trva, i_class_least]):  # length is only 1 !\n",
    "                idx_tr = idx_trva[idx_tr_ss2]\n",
    "                idx_va = idx_trva[idx_va_ss2]\n",
    "                for i_class in range(n_classes):\n",
    "                    tr_percent = 1.0 * np.sum(y[idx_tr, i_class]) / np.sum(y[:, i_class])\n",
    "                    va_percent = 1.0 * np.sum(y[idx_va, i_class]) / np.sum(y[:, i_class])\n",
    "                    if va_percent < 0.5 * test_ratio or \\\n",
    "                                    tr_percent < 0.5:\n",
    "                        success_flag = False\n",
    "                        break\n",
    "                if not success_flag:\n",
    "                    break\n",
    "            if not success_flag:\n",
    "                continue\n",
    "        if not success_flag:\n",
    "            continue\n",
    "        idx_list[i_trial] = [idx_tr, idx_va, idx_te]\n",
    "        i_trial += 1\n",
    "    return idx_list\n",
    "\n",
    "\n",
    "def make_splits(y, nfold):\n",
    "    if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "        return try_making_splits(y, nfold)\n",
    "    assert nfold > 2\n",
    "    skf = StratifiedKFold(nfold, shuffle=True, random_state=0)\n",
    "    idx_trva_list = []\n",
    "    idx_te_list = []\n",
    "    for idx_tr, idx_te in skf.split(np.zeros(np.array(y).flatten().shape[0]), np.array(y).flatten()):\n",
    "        idx_trva_list.append(idx_tr)\n",
    "        idx_te_list.append(idx_te)\n",
    "\n",
    "    idx_list = np.empty([nfold, 3], dtype=object)\n",
    "    for i in range(nfold):\n",
    "        idx_list[i][0] = np.setdiff1d(idx_trva_list[i], idx_te_list[(i + 1) % nfold], True)\n",
    "        idx_list[i][1] = idx_te_list[(i + 1) % nfold]\n",
    "        idx_list[i][2] = idx_te_list[i]\n",
    "    return idx_list\n",
    "\n",
    "# def get_icd9_subcat_label(icd9_str):\n",
    "#     ss = icd9_str.split('.')[0]\n",
    "#     idx_lb = max(np.where(ss >= subcat_lbs)[0])\n",
    "#     idx_ub = min(np.where(ss[:4] <= subcat_ubs)[0])\n",
    "#     if idx_lb != idx_ub:\n",
    "#         print(idx_lb, idx_ub, icd9_str, ss)\n",
    "#     #assert idx_lb == idx_ub\n",
    "#     return idx_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data file\n",
      "load icd9 label file\n",
      "load mor label file\n",
      "load admission features\n",
      "load mortality labels\n",
      "# of samples: 31912\n",
      "[]\n",
      "# of samples > 48 hours: 31912\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "#### Main ####\n",
    "# DATA_NAME = 'mimic319k48h'\n",
    "# Settings for task, model, path, etc\n",
    "# working_path = r'../..'\n",
    "HRS = 48\n",
    "\n",
    "working_path = '/media/data/mimic/hf_admdata_17f/%dhrs/' % HRS\n",
    "# raw_data_path = os.path.join(working_path, 'data', DATA_NAME, 'raw')\n",
    "# processed_data_path = os.path.join(working_path, 'data', DATA_NAME)\n",
    "raw_data_path = working_path\n",
    "processed_data_path = os.path.join(working_path, 'series')\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "\n",
    "LAB_EVENTS_IDX = np.array([0,1,2,3,4,5,7,8,9,10,11,12]) # labevents and chartevents\n",
    "\n",
    "print('load data file')\n",
    "data_all = np.empty([0], dtype=object)\n",
    "for datanpz_file_name in ['DB_merged_%dhrs.npy' % HRS]:\n",
    "    datanpz_file_pathname = os.path.join(raw_data_path,\n",
    "                                         datanpz_file_name)\n",
    "    data_all = np.concatenate((data_all, np.load(datanpz_file_pathname, allow_pickle=True)))\n",
    "\n",
    "print('load icd9 label file')\n",
    "label_icd9_all = np.empty([0], dtype=object)\n",
    "for label_icd9_npz_file_name in ['ICD9-%dhrs.npy' % HRS]:\n",
    "    label_icd9_npz_file_pathname = os.path.join(raw_data_path, \n",
    "                                                label_icd9_npz_file_name)\n",
    "    label_icd9_all = np.concatenate((label_icd9_all, \n",
    "                                    np.load(label_icd9_npz_file_pathname, allow_pickle=True)))\n",
    "\n",
    "# print('load icd9 subcat list file')\n",
    "# subcat_lbs = []\n",
    "# subcat_ubs = []\n",
    "# with open(os.path.join(raw_data_path, 'ICD9_subcat.csv'), 'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         subcat_id, subcat_lb, subcat_ub = line.split(',')\n",
    "#         subcat_lbs.append(subcat_lb)\n",
    "#         subcat_ubs.append(subcat_ub)\n",
    "#     subcat_lbs = np.array(subcat_lbs)\n",
    "#     subcat_ubs = np.array(subcat_ubs)\n",
    "\n",
    "print('load mor label file')\n",
    "label_mor_all = None\n",
    "for label_mor_npz_file_name in ['AGE_LOS_MORTALITY_%dhrs.npy' % HRS]:\n",
    "    label_mor_npz_file_pathname = os.path.join(raw_data_path,\n",
    "                                               label_mor_npz_file_name)\n",
    "    if label_mor_all is None:\n",
    "        label_mor_all = np.load(label_mor_npz_file_pathname, allow_pickle=True)\n",
    "    else:\n",
    "        label_mor_all = np.concatenate((label_mor_all, \n",
    "                                        np.load(label_mor_npz_file_pathname, allow_pickle=True)))\n",
    "        \n",
    "print('load admission features')\n",
    "adm_features_all = np.load(os.path.join(raw_data_path, 'ADM_FEATURES_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "\n",
    "print('load mortality labels')\n",
    "adm_labels_all = np.load(os.path.join(raw_data_path, 'ADM_LABELS_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "\n",
    "N_all = len(data_all)\n",
    "print('# of samples:', N_all)\n",
    "# get per-frame samples;\n",
    "# imputed-normed-ep (imputation here):    \n",
    "#               ep_tdata_raw, ep_tdata: N * [ti * D]\n",
    "#               ep_tdata_mean, ep_tdata_std: D\n",
    "# normed-ep:    X_t, X_t_mask, deltaT_t: N * [ti * D]\n",
    "#               T_t: N * [ti]\n",
    "X_raw_p48 = np.array([np.array(xx, dtype=float)[:,:-2] for xx in data_all])\n",
    "tsraw_p48 = np.array([np.array(xx, dtype=float)[:,-2] for xx in data_all])\n",
    "del data_all\n",
    "\n",
    "idx_x = np.where([(tt[-1] - tt[0]) > 1.0*60*60*HRS for tt in tsraw_p48])[0]\n",
    "idx_x2 = np.where([(tt[-1] - tt[0]) <= 1.0*60*60*HRS for tt in tsraw_p48])[0]\n",
    "print(idx_x2)\n",
    "N = len(idx_x)\n",
    "print('# of samples > %s hours:' % (HRS), N)\n",
    "assert N_all == N\n",
    "X_raw = X_raw_p48[idx_x]\n",
    "tsraw = tsraw_p48[idx_x]\n",
    "label_icd9_all = label_icd9_all[idx_x]\n",
    "label_mor_all = label_mor_all[idx_x]\n",
    "adm_features_all = adm_features_all[idx_x]\n",
    "adm_labels_all = adm_labels_all[idx_x]\n",
    "\n",
    "for i_n in range(N):\n",
    "    #print i_n\n",
    "    if i_n % 20 == 0:\n",
    "        print('.', end='')\n",
    "        sys.stdout.flush()\n",
    "    for i_t in range(len(X_raw[i_n])):\n",
    "        for i_d in range(len(X_raw[i_n][i_t])):\n",
    "            if X_raw[i_n][i_t][i_d] is None:\n",
    "                X_raw[i_n][i_t][i_d] = np.nan\n",
    "X_raw_all = np.concatenate(X_raw)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ array([ -12335.,   -4535.,    4165.,    4345.,    4405.,    7225.,\n",
      "          7285.,    7345.,    7945.,   10945.,   11545.,   15145.,\n",
      "         18745.,   22345.,   24205.,   24385.,   25945.,   27505.,\n",
      "         29545.,   33145.,   36745.,   40345.,   41365.,   43945.,\n",
      "         44005.,   44665.,   47545.,   51145.,   54745.,   55285.,\n",
      "         56905.,   58345.,   58405.,   61345.,   61945.,   65545.,\n",
      "         67345.,   69145.,   72745.,   74785.,   76345.,   78745.,\n",
      "         79945.,   83545.,   84205.,   87145.,   87265.,   90745.,\n",
      "         91465.,   91645.,   94345.,   97225.,   97945.,  101545.,\n",
      "        105145.,  107185.,  108745.,  112345.,  114985.,  115945.,\n",
      "        116305.,  119545.,  122425.,  123145.,  126745.,  127645.,\n",
      "        128485.,  130345.,  133945.,  134905.,  137545.,  140905.,\n",
      "        141145.,  144745.,  145765.,  146965.,  148345.,  151165.,\n",
      "        151945.,  155545.,  159145.,  159505.,  159805.,  162745.,\n",
      "        164125.,  166345.,  167305.,  167545.,  169945.,  171265.,\n",
      "        173545.,  173785.,  177145.,  180745.,  184285.,  184345.,\n",
      "        187945.,  188485.,  191545.,  195145.,  198745.,  202345.,\n",
      "        205945.,  209545.,  212785.,  213145.,  216685.,  216745.,\n",
      "        216805.,  220345.,  221605.,  223945.,  227545.,  229345.,\n",
      "        231145.,  231625.,  231745.,  234745.,  238345.,  245545.,\n",
      "        247885.,  252745.,  253585.,  263545.,  264505.,  268645.,\n",
      "        285145.,  287845.,  289405.,  291745.,  292345.,  295945.,\n",
      "        299545.,  300805.,  303145.,  303205.,  303565.,  303625.,\n",
      "        306745.,  310345.,  313945.,  317545.,  321145.,  331945.,\n",
      "        332545.,  340345.,  341185.,  346345.,  347425.,  360745.,\n",
      "        411745.,  496645.])\n",
      " array([ -1.56150000e+04,  -8.59500000e+03,   5.85000000e+02,\n",
      "         2.38500000e+03,   4.18500000e+03,   7.78500000e+03,\n",
      "         1.13850000e+04,   1.45050000e+04,   1.49850000e+04,\n",
      "         1.85850000e+04,   2.21850000e+04,   2.38650000e+04,\n",
      "         2.57850000e+04,   2.93850000e+04,   3.29850000e+04,\n",
      "         3.65850000e+04,   4.01850000e+04,   4.37850000e+04,\n",
      "         4.73850000e+04,   5.09850000e+04,   5.45850000e+04,\n",
      "         5.81850000e+04,   6.17850000e+04,   6.53850000e+04,\n",
      "         6.89850000e+04,   7.25850000e+04,   7.61850000e+04,\n",
      "         7.97850000e+04,   8.33850000e+04,   8.69850000e+04,\n",
      "         9.05850000e+04,   9.41850000e+04,   9.77850000e+04,\n",
      "         1.01385000e+05,   1.04985000e+05,   1.08585000e+05,\n",
      "         1.12185000e+05,   1.15785000e+05,   1.19385000e+05,\n",
      "         1.22985000e+05,   1.26585000e+05,   1.30185000e+05,\n",
      "         1.31985000e+05,   1.32285000e+05,   1.33785000e+05,\n",
      "         1.37385000e+05,   1.40085000e+05,   1.40985000e+05,\n",
      "         1.44585000e+05,   1.48185000e+05,   1.51785000e+05,\n",
      "         1.55265000e+05,   1.55385000e+05,   1.58985000e+05,\n",
      "         1.62585000e+05,   1.66185000e+05,   1.69785000e+05,\n",
      "         1.73385000e+05,   1.76985000e+05,   1.80585000e+05,\n",
      "         1.84185000e+05,   1.87785000e+05,   1.91385000e+05,\n",
      "         1.94985000e+05,   1.98585000e+05,   2.02185000e+05,\n",
      "         2.05785000e+05,   2.09385000e+05,   2.12985000e+05,\n",
      "         2.16585000e+05,   2.20185000e+05,   2.23785000e+05,\n",
      "         2.27385000e+05,   2.30985000e+05,   2.31825000e+05,\n",
      "         2.34585000e+05,   2.38185000e+05,   2.41785000e+05,\n",
      "         2.45385000e+05,   2.48985000e+05,   2.52585000e+05,\n",
      "         2.56185000e+05,   2.59785000e+05,   2.70585000e+05,\n",
      "         2.74185000e+05,   2.77785000e+05,   2.81385000e+05,\n",
      "         2.84985000e+05,   2.88585000e+05,   2.92185000e+05,\n",
      "         2.95785000e+05,   2.99385000e+05,   3.02985000e+05,\n",
      "         3.06585000e+05,   3.10185000e+05,   3.13785000e+05,\n",
      "         3.17385000e+05,   3.19785000e+05,   3.20985000e+05,\n",
      "         3.24585000e+05,   3.28185000e+05,   3.31785000e+05,\n",
      "         3.35385000e+05,   3.38985000e+05,   3.42585000e+05,\n",
      "         3.46185000e+05,   3.49785000e+05,   3.53385000e+05,\n",
      "         3.56985000e+05,   3.60585000e+05,   3.64185000e+05,\n",
      "         3.67785000e+05,   3.71385000e+05,   3.74985000e+05,\n",
      "         3.78585000e+05,   3.82185000e+05,   3.85785000e+05,\n",
      "         3.89385000e+05,   3.92985000e+05,   3.94185000e+05,\n",
      "         3.96585000e+05,   4.00185000e+05,   4.03785000e+05,\n",
      "         4.07385000e+05,   4.10985000e+05,   4.14585000e+05,\n",
      "         4.18185000e+05,   4.21785000e+05,   4.25385000e+05,\n",
      "         4.86585000e+05,   5.73885000e+05,   6.59385000e+05,\n",
      "         7.45785000e+05,   8.28585000e+05,   9.09585000e+05,\n",
      "         9.86865000e+05])\n",
      " array([    517.,     757.,    1057.,    1357.,    1657.,    1957.,\n",
      "          2257.,    2557.,    3457.,    6157.,    9757.,   10657.,\n",
      "         13357.,   16957.,   20557.,   24157.,   27757.,   31357.,\n",
      "         34957.,   38557.,   42157.,   45757.,   49357.,   52957.,\n",
      "         56557.,   59257.,   60157.,   63757.,   67357.,   70957.,\n",
      "         74557.,   78157.,   79057.,   81757.,   83557.,   85357.,\n",
      "         87157.,   88957.,   92557.,   96157.,   99757.,  100657.,\n",
      "        101557.,  103357.,  106957.,  110557.,  158257.,  184957.,\n",
      "        185557.,  193357.,  194257.,  195157.,  196957.,  198757.,\n",
      "        199357.,  200557.,  205957.,  207757.,  211357.,  214957.,\n",
      "        218557.,  222157.,  225757.,  229357.,  232957.,  235957.,\n",
      "        236557.,  240157.,  243757.,  247357.,  250957.,  252757.,\n",
      "        258157.,  265357.,  270757.,  276157.,  279757.,  285157.,\n",
      "        294157.,  297757.,  301357.,  308557.,  315517.,  315757.,\n",
      "        322957.,  330157.,  337357.,  344557.,  345457.,  349957.,\n",
      "        351757.,  420757.,  505357.])\n",
      " ...,\n",
      " array([   3252.,    9132.,   12552.,   17232.,   21972.,   26232.,\n",
      "         28452.,   29352.,   30252.,   30372.,   31152.,   32052.,\n",
      "         32952.,   34752.,   36432.,   36552.,   40152.,   43752.,\n",
      "         47352.,   50952.,   52932.,   54552.,   58152.,   61752.,\n",
      "         62052.,   65352.,   68172.,   68952.,   72552.,   76152.,\n",
      "         79752.,   83352.,   86952.,   90552.,   93312.,   94152.,\n",
      "         97752.,  101352.,  104952.,  108552.,  112152.,  115752.,\n",
      "        119352.,  122952.,  126552.,  130152.,  133752.,  137352.,\n",
      "        138072.,  140952.,  144552.,  147252.,  151752.,  153552.,\n",
      "        158952.,  166152.,  173172.,  173352.,  180552.,  184152.,\n",
      "        187752.,  189252.,  194952.,  202152.,  205752.,  209352.,\n",
      "        212952.,  216552.,  220812.,  223752.,  227352.,  230952.,\n",
      "        232752.,  232812.,  238152.,  241752.,  321552.,  494352.,\n",
      "        505452.,  578052.])\n",
      " array([   -759.,    5481.,    8901.,   10461.,   11361.,   13821.,\n",
      "         14121.,   14421.,   14781.,   15021.,   15921.,   16821.,\n",
      "         17721.,   18621.,   19521.,   20421.,   21321.,   22221.,\n",
      "         23121.,   23421.,   24021.,   24921.,   25821.,   26721.,\n",
      "         27381.,   27621.,   28521.,   30321.,   32121.,   34701.,\n",
      "         35721.,   39321.,   42921.,   46521.,   47121.,   48321.,\n",
      "         50121.,   52641.,   53721.,   55521.,   57321.,   60921.,\n",
      "         64521.,   66321.,   68121.,   69921.,   71721.,   75321.,\n",
      "         78921.,   82521.,   86121.,   89721.,  152421.,  252621.,\n",
      "        323721.,  339021.])\n",
      " array([ -5.53000000e+03,   2.30000000e+02,   3.50000000e+02,\n",
      "         4.70000000e+02,   3.53000000e+03,   7.13000000e+03,\n",
      "         1.07300000e+04,   1.43300000e+04,   1.79300000e+04,\n",
      "         2.15300000e+04,   2.51300000e+04,   2.87300000e+04,\n",
      "         2.87900000e+04,   3.10100000e+04,   3.23300000e+04,\n",
      "         3.59300000e+04,   3.89900000e+04,   3.95300000e+04,\n",
      "         4.31300000e+04,   4.67300000e+04,   4.93100000e+04,\n",
      "         5.03300000e+04,   5.39300000e+04,   5.75300000e+04,\n",
      "         5.93300000e+04,   6.03500000e+04,   6.11300000e+04,\n",
      "         6.29300000e+04,   6.38300000e+04,   6.47300000e+04,\n",
      "         6.56300000e+04,   6.57500000e+04,   6.83300000e+04,\n",
      "         7.19300000e+04,   7.21100000e+04,   7.55300000e+04,\n",
      "         7.91300000e+04,   8.27300000e+04,   8.33300000e+04,\n",
      "         8.63300000e+04,   8.99300000e+04,   9.09500000e+04,\n",
      "         9.35300000e+04,   9.46700000e+04,   9.71300000e+04,\n",
      "         1.00730000e+05,   1.04330000e+05,   1.04390000e+05,\n",
      "         1.07930000e+05,   1.11530000e+05,   1.15130000e+05,\n",
      "         1.15190000e+05,   1.18730000e+05,   1.18970000e+05,\n",
      "         1.22330000e+05,   1.25930000e+05,   1.29530000e+05,\n",
      "         1.33130000e+05,   1.36730000e+05,   1.40330000e+05,\n",
      "         1.43930000e+05,   1.47530000e+05,   1.51130000e+05,\n",
      "         1.54730000e+05,   1.58330000e+05,   1.61930000e+05,\n",
      "         1.65530000e+05,   1.69130000e+05,   1.72730000e+05,\n",
      "         1.76330000e+05,   1.79930000e+05,   1.83530000e+05,\n",
      "         1.87130000e+05,   1.90730000e+05,   1.94330000e+05,\n",
      "         1.97930000e+05,   2.01530000e+05,   2.01590000e+05,\n",
      "         2.05130000e+05,   2.05610000e+05,   2.08730000e+05,\n",
      "         2.09330000e+05,   2.09630000e+05,   2.12330000e+05,\n",
      "         2.15930000e+05,   2.19530000e+05,   2.23130000e+05,\n",
      "         2.26730000e+05,   2.30330000e+05,   2.30510000e+05,\n",
      "         2.33930000e+05,   2.37530000e+05,   2.41130000e+05,\n",
      "         2.44730000e+05,   2.48330000e+05,   2.51930000e+05,\n",
      "         2.55530000e+05,   2.59130000e+05,   2.62730000e+05,\n",
      "         2.66330000e+05,   2.69930000e+05,   2.73530000e+05,\n",
      "         2.77130000e+05,   2.80730000e+05,   2.84330000e+05,\n",
      "         2.87930000e+05,   2.87990000e+05,   2.91530000e+05,\n",
      "         2.93210000e+05,   2.95130000e+05,   2.98730000e+05,\n",
      "         3.02330000e+05,   3.05930000e+05,   3.09530000e+05,\n",
      "         3.13130000e+05,   3.16730000e+05,   3.20330000e+05,\n",
      "         3.20930000e+05,   3.23930000e+05,   3.27530000e+05])]\n"
     ]
    }
   ],
   "source": [
    "print(tsraw_p48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get mr and kept idx\n"
     ]
    }
   ],
   "source": [
    "# remove the columns with less observations\n",
    "print('get mr and kept idx')\n",
    "val_mr = np.sum(np.isnan(X_raw_all), axis=0) * 1.0 / X_raw_all.shape[0]\n",
    "keep_val_idx = val_mr < 1-5e-4\n",
    "keep_val_idx_list = np.where(keep_val_idx)\n",
    "X_raw_all_kept = X_raw_all[:,keep_val_idx]\n",
    "X_raw_kept = np.array([xx[:, keep_val_idx] for xx in X_raw])\n",
    "lab_events_idx = LAB_EVENTS_IDX\n",
    "\n",
    "del X_raw_all\n",
    "del X_raw\n",
    "\n",
    "# X_raw_all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the mean value in the first HRS hours, used for SuperLearner\n",
    "# First get the mean of pao2 and fio2, then calc the ratio!!!\n",
    "PAO2_VAR = 4\n",
    "FIO2_VAR = 5\n",
    "RATIO_VAR = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get mean and std for tdata\n",
      "get X_new and t_new\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "print('get mean and std for tdata')\n",
    "n_temporal_var = X_raw_all_kept.shape[1]    # last frame is time t in seconds\n",
    "ep_tdata_mean = np.nanmean(X_raw_all_kept, axis=0)\n",
    "ep_tdata_std = np.nanstd(X_raw_all_kept, axis=0)\n",
    "del X_raw_all_kept\n",
    "\n",
    "# get ep data with mask and deltaT\n",
    "# 0-mean, 1-std, merge observations within 5 mins\n",
    "merging_mins = 5\n",
    "print('get X_new and t_new')\n",
    "X_new = np.empty([N], dtype=object)\n",
    "t_new = np.empty([N], dtype=object)\n",
    "for i in range(N):\n",
    "    if i % 20 == 0:\n",
    "        print('.',end='')\n",
    "        sys.stdout.flush()\n",
    "    tsraw[i] = tsraw[i].flatten()\n",
    "    t = 0\n",
    "    X_new[i] = []\n",
    "    t_new[i] = []\n",
    "    while t < len(tsraw[i]):\n",
    "        t1 = t+1\n",
    "        while t1 < len(tsraw[i]) and tsraw[i][t1] - tsraw[i][t] <= merging_mins*60:\n",
    "            t1 += 1\n",
    "        # merge [t:t1]\n",
    "#         X_new[i].append(\n",
    "#             (np.nanmean(X_raw_kept[i][t:t1,:], axis=0) - ep_tdata_mean) \\\n",
    "#                 /ep_tdata_std\n",
    "#             )\n",
    "        # Here we do not normalize the data!!!\n",
    "        X_new[i].append(\n",
    "            np.nanmean(X_raw_kept[i][t:t1,:], axis=0)\n",
    "            )\n",
    "        # X_new[i].append(np.nanmean(X_raw_kept[i][t:t1,:], axis=0))\n",
    "        t_new[i].append(int((tsraw[i][t1-1]+tsraw[i][t])/2))\n",
    "        t = t1\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('get X_t, mask, etc')\n",
    "X_t = np.empty([N], dtype=object)        # N * [t*d]\n",
    "X_t_mask = np.empty([N], dtype=object)   # N * [t*d]\n",
    "T_t = t_new                                 # N * [t]\n",
    "deltaT_t = np.empty([N], dtype=object)   # N * [t*d]\n",
    "for i in range(N):\n",
    "    if i % 20 == 0:\n",
    "        print('.',end='')\n",
    "        sys.stdout.flush()\n",
    "    X_t[i] = np.vstack(X_new[i])\n",
    "    X_t_mask[i] = 1-np.isnan(X_t[i]).astype('int8')\n",
    "    X_t[i][np.isnan(X_t[i])] = 0\n",
    "    deltaT_t[i] = np.zeros_like(X_t[i], dtype=int)\n",
    "    deltaT_t[i][0,:] = 0\n",
    "    for i_t in range(1, len(T_t[i])):\n",
    "        deltaT_t[i][i_t,:] = T_t[i][i_t] - T_t[i][i_t-1] + \\\n",
    "            (1-X_t_mask[i][i_t-1,:]) * deltaT_t[i][i_t-1,:]\n",
    "print('done!')\n",
    "del X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract subcat labels\n",
    "# for i_n, label_i in enumerate(label_icd9_all):\n",
    "#     for i_li, label_vec in enumerate(label_i):\n",
    "#         subcat = get_icd9_subcat_label(label_vct[2])\n",
    "#         label_i[i_li].append(subcat)\n",
    "#     label_icd9_all[i_n] = label_i\n",
    "        \n",
    "# get labels\n",
    "print('get labels')\n",
    "class_icd9_counts = np.bincount(\n",
    "    np.concatenate(label_icd9_all)[:,3].astype(int))\n",
    "class_icd9_list = np.where(class_icd9_counts > 10)[0]\n",
    "class_icd9_list.sort()\n",
    "\n",
    "# class_icd9_subcat_counts = np.bincount(\n",
    "#     np.concatenate(label_icd9_all)[:,4].astype(int))\n",
    "# class_icd9_subcat_list = np.where(class_icd9_subcat_counts >= 200)[0]\n",
    "# class_icd9_subcat_list.sort()\n",
    "\n",
    "n_class_icd9 = class_icd9_list.shape[0]\n",
    "# n_class_icd9_subcat = class_icd9_subcat_list.shape[0]\n",
    "y_icd9 = np.zeros([N, n_class_icd9], dtype=int)\n",
    "# y_icd9_subcat = np.zeros([N, n_class_icd9_subcat], dtype=int)\n",
    "for i_n, label_i in enumerate(label_icd9_all):\n",
    "        for label_vec in label_i:\n",
    "            class_idx = np.array(\n",
    "                [cl == label_vec[3] for cl in class_icd9_list],\n",
    "                dtype=bool)\n",
    "            y_icd9[i_n][class_idx] = 1\n",
    "#             subcat_idx = np.array(\n",
    "#                 [cl == label_vec[4] for cl in class_icd9_subcat_list],\n",
    "#                 dtype=bool)\n",
    "#             y_icd9_subcat[i_n][subcat_idx] = 1\n",
    "\n",
    "y_mor = np.expand_dims(np.array(label_mor_all[:,4], dtype=int), axis=1)\n",
    "age_days = label_mor_all[:, 2]\n",
    "y_los = label_mor_all[:, 3]\n",
    "            \n",
    "# print('# of class, subcat:', n_class_icd9, n_class_icd9_subcat)\n",
    "print('# of class, subcat:')\n",
    "\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep-stats.npz'), \n",
    "         class_icd9_list=class_icd9_list, \n",
    "         class_icd9_counts=class_icd9_counts,\n",
    "#          class_icd9_subcat_list=class_icd9_subcat_list,\n",
    "#          class_icd9_subcat_counts=class_icd9_subcat_counts,\n",
    "         keep_val_idx_list=keep_val_idx_list, \n",
    "         ep_tdata_mean=ep_tdata_mean, ep_tdata_std=ep_tdata_std,\n",
    "         n_class_icd9=n_class_icd9, \n",
    "#          n_class_icd9_subcat=n_class_icd9_subcat,\n",
    "         N=N, val_mr=val_mr, idx_x=idx_x, age_days=age_days)\n",
    "\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep.npz'), \n",
    "         X_t=X_t,X_t_mask=X_t_mask,T_t=T_t,deltaT_t=deltaT_t,\n",
    "         y_icd9=y_icd9, y_mor=y_mor, adm_features_all=adm_features_all, adm_labels_all=adm_labels_all,y_los=y_los)\n",
    "# , y_icd9_subcat=y_icd9_subcat)\n",
    "\n",
    "del X_t, X_t_mask, deltaT_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ep_origin = np.load(os.path.join(processed_data_path, 'normed-ep.npz'), allow_pickle=True)\n",
    "# Here we merge pao2 and fio2 and get pf ratio\n",
    "X_t_ratio = []\n",
    "X_t_ratio_mask = []\n",
    "T_t_ratio = []\n",
    "deltaT_t_ratio = []\n",
    "X_t_origin, X_t_origin_mask, T_t_origin, deltaT_t_origin = ep_origin['X_t'], ep_origin['X_t_mask'], ep_origin['T_t'], ep_origin['deltaT_t']\n",
    "for t in range(X_t_origin.shape[0]):\n",
    "    if t % 20 == 0:\n",
    "        print('.', end='')\n",
    "    xto = X_t_origin[t]\n",
    "    xtom = X_t_origin_mask[t]\n",
    "    tto = T_t_origin[t]\n",
    "    dto = deltaT_t_origin[t]\n",
    "    ratio_shape = (xto.shape[0], xto.shape[1] - 1)\n",
    "    xto_ratio = np.full(ratio_shape, np.nan)\n",
    "    xtom_ratio = np.full(ratio_shape, np.nan)\n",
    "    tto_ratio = tto\n",
    "    dto_ratio = np.full(ratio_shape, np.nan)\n",
    "    # keep others\n",
    "    for itratio, it in zip([xto_ratio, xtom_ratio, dto_ratio],[xto, xtom, dto]):\n",
    "        itratio[:, :PAO2_VAR] = it[:, :PAO2_VAR]\n",
    "        itratio[:, FIO2_VAR:] = it[:, FIO2_VAR + 1:]\n",
    "    # fix the ratio part\n",
    "    xto_ratio[:, PAO2_VAR] = xto[:, PAO2_VAR] / xto[:, FIO2_VAR]\n",
    "    xto_ratio[np.isinf(xto_ratio)] = np.nan\n",
    "    xtom_ratio[:, PAO2_VAR] = np.logical_and(xtom[:, PAO2_VAR], xtom[:, FIO2_VAR])\n",
    "    dto_ratio[:, PAO2_VAR] = np.zeros_like(dto[:, PAO2_VAR])\n",
    "    for i_t in range(1, len(tto_ratio)):\n",
    "        dto_ratio[i_t,PAO2_VAR] = tto_ratio[i_t] - tto_ratio[i_t-1] + \\\n",
    "            (1-xtom_ratio[i_t-1,PAO2_VAR]) * dto_ratio[i_t-1,PAO2_VAR]\n",
    "    X_t_ratio.append(xto_ratio)\n",
    "    X_t_ratio_mask.append(xtom_ratio)\n",
    "    T_t_ratio.append(tto_ratio)\n",
    "    deltaT_t_ratio.append(dto_ratio)\n",
    "X_t_ratio = np.array(X_t_ratio, dtype=object)\n",
    "X_t_ratio_mask = np.array(X_t_ratio_mask, dtype=object)\n",
    "T_t_ratio = np.array(T_t_ratio, dtype=object)\n",
    "deltaT_t_ratio = np.array(deltaT_t_ratio, dtype=object)\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep-ratio.npz'), \n",
    "         X_t=X_t_ratio,X_t_mask=X_t_ratio_mask,T_t=T_t_ratio,deltaT_t=deltaT_t_ratio,\n",
    "         y_icd9=ep_origin['y_icd9'], y_mor=ep_origin['y_mor'], adm_features_all=ep_origin['adm_features_all'], adm_labels_all=ep_origin['adm_labels_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get first N hours data\n",
    "# one data sample for one patient\n",
    "# hours_list = [(2, 24), (1, 24), (1, 48), (2, 48)]\n",
    "hours_list = [(2, HRS), (1, HRS)]\n",
    "for n_sample_hour, n_full_hour in hours_list:\n",
    "    print('get X_miss', n_sample_hour, n_full_hour)\n",
    "    #n_sample_hour = 2\n",
    "    #n_full_hour = HRS\n",
    "    n_time_step = int(n_full_hour / n_sample_hour)\n",
    "    # get X_miss first from X_raw_all_kept and tsraw, (sampled)\n",
    "    X_miss = np.empty([N], dtype = object)\n",
    "    T_miss = np.zeros([N], dtype = int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        T_miss[i_n] = math.ceil(\n",
    "            (tsraw[i_n][-1]-tsraw[i_n][0])*1.0/(60*60*n_sample_hour))\n",
    "        X_miss[i_n] = np.zeros([T_miss[i_n], n_temporal_var], dtype=float)\n",
    "        for i_t in range(T_miss[i_n]):\n",
    "            t_idx = np.logical_and(\n",
    "                (tsraw[i_n]-tsraw[i_n][0]) >= i_t*(60*60*n_sample_hour),\n",
    "                (tsraw[i_n]-tsraw[i_n][0]) <= (1+i_t) * (60*60*n_sample_hour))\n",
    "            X_raw_thist = X_raw_kept[i_n][t_idx, :]\n",
    "            # Here we do not normalize the data!!!\n",
    "#             X_miss[i_n][i_t,:] = \\\n",
    "#                 (np.nanmean(X_raw_thist, axis=0) - ep_tdata_mean) / ep_tdata_std\n",
    "            X_miss[i_n][i_t,:] = np.nanmean(X_raw_thist, axis=0)\n",
    "    print('done!')\n",
    "    # X_imputed: do forward/backward imputing from X_miss for lab events\n",
    "    #            do mean imputing for other events\n",
    "    print('get X_imputed')\n",
    "    X_imputed = deepcopy(X_miss)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        i_n_mean = np.nanmean(X_imputed[i_n], axis=0)\n",
    "        for i_t in range(1, T_miss[i_n]):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    if keep_val_idx_list[0][i_d] in lab_events_idx:\n",
    "                        X_imputed[i_n][i_t, i_d] = X_imputed[i_n][i_t-1, i_d]\n",
    "        for i_t in range(T_miss[i_n]-2, -1, -1):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    if keep_val_idx_list[0][i_d] in lab_events_idx:\n",
    "                        X_imputed[i_n][i_t, i_d] = X_imputed[i_n][i_t+1, i_d]\n",
    "        # X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "        # Here we use mean value of each feature in current time series to impute nans\n",
    "        for i_t in range(0, T_miss[i_n]):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    X_imputed[i_n][i_t, i_d] = i_n_mean[i_d]\n",
    "        # for values which are still none, just impute with 0\n",
    "#         X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "    print('done!')\n",
    "        \n",
    "    # get first # hours, for both data and masking\n",
    "    print('get ep_tdata')\n",
    "    ep_tdata = np.zeros([N, n_time_step, n_temporal_var], dtype=float)\n",
    "    ep_tdata_masking = np.zeros_like(ep_tdata, dtype=int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        xx_imp = X_imputed[i_n]\n",
    "        xx_mis = X_miss[i_n]\n",
    "        tt_min = min(n_time_step, len(xx_imp))\n",
    "        assert tt_min > 0\n",
    "        ep_tdata[i_n, :tt_min, :] = xx_imp[:tt_min, :]\n",
    "        ep_tdata[i_n, tt_min:, :] = ep_tdata[i_n, tt_min-1, :][None, :]\n",
    "        ep_tdata_masking[i_n, :tt_min, :] = \\\n",
    "            (~np.isnan(xx_mis[:tt_min, :])).astype(int)\n",
    "    print('done!')\n",
    "    \n",
    "    # After imputation, calc the pf ratio!!!\n",
    "    print('calculating pao2/fio2 ratio...')\n",
    "    ep_tdata_withr = np.zeros([N, n_time_step, n_temporal_var - 1], dtype=float)\n",
    "    ep_tdata_masking_withr = np.zeros_like(ep_tdata_withr, dtype=int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        pfratio = ep_tdata[i_n, :, PAO2_VAR] / ep_tdata[i_n, :, FIO2_VAR]\n",
    "        pfratio_masking = np.logical_and(ep_tdata_masking[i_n, :, PAO2_VAR] == 1,\n",
    "                                        ep_tdata_masking[i_n, :, FIO2_VAR] == 1).astype(int)\n",
    "        ep_tdata_withr[i_n, :, :PAO2_VAR] = ep_tdata[i_n, :, :PAO2_VAR]\n",
    "        ep_tdata_withr[i_n, :, PAO2_VAR] = pfratio\n",
    "        ep_tdata_withr[i_n, :, FIO2_VAR:] = ep_tdata[i_n, :, FIO2_VAR + 1:]\n",
    "        ep_tdata_masking_withr[i_n, :, :PAO2_VAR] = ep_tdata_masking[i_n, :, :PAO2_VAR]\n",
    "        ep_tdata_masking_withr[i_n, :, PAO2_VAR] = pfratio_masking\n",
    "        ep_tdata_masking_withr[i_n, :, FIO2_VAR:] = ep_tdata_masking[i_n, :, FIO2_VAR + 1:]\n",
    "    ep_tdata_withr[np.isinf(ep_tdata_withr)] = np.nan\n",
    "#     ep_tdata_masking_withr[np.isnan(ep_tdata_withr)] = 0\n",
    "    print('done!')\n",
    "    \n",
    "    # After calc ratio, impute the ratio!!!\n",
    "    print('imputing pao2/fio2 ratio...')\n",
    "    print('get X_withr_imputed')\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        i_n_mean = np.nanmean(ep_tdata_withr[i_n], axis=0)\n",
    "        tslen = ep_tdata_withr[i_n].shape[0]\n",
    "        for i_t in range(1, tslen):\n",
    "            for i_d in [PAO2_VAR]:\n",
    "                if np.isnan(ep_tdata_withr[i_n, i_t, i_d]):\n",
    "                    ep_tdata_withr[i_n, i_t, i_d] = ep_tdata_withr[i_n, i_t - 1, i_d]\n",
    "        for i_t in range(tslen-2, -1, -1):\n",
    "            for i_d in [PAO2_VAR]:\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    ep_tdata_withr[i_n, i_t, i_d] = ep_tdata_withr[i_n, i_t+1, i_d]\n",
    "        # X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "        # Here we use mean value of each feature in current time series to impute nans\n",
    "        for i_t in range(0, tslen):\n",
    "            for i_d in [PAO2_VAR]:\n",
    "                if np.isnan(ep_tdata_withr[i_n, i_t, i_d]):\n",
    "                    ep_tdata_withr[i_n, i_t, i_d] = i_n_mean[i_d]\n",
    "    # for values which are still none, just impute with 0\n",
    "#     ep_tdata_withr[np.isnan(ep_tdata_withr)] = 0\n",
    "    print('done!')\n",
    "    \n",
    "#     assert ep_tdata_withr[np.isnan(ep_tdata_withr)].shape == (0,)\n",
    "    \n",
    "    n_temporal_var_withr = n_temporal_var - 1\n",
    "    ep_data_withr = np.reshape(ep_tdata_withr, [N, n_time_step*n_temporal_var_withr])\n",
    "    ep_data_masking_withr = np.reshape(ep_tdata_masking_withr, [N, n_time_step*n_temporal_var_withr])\n",
    "    \n",
    "    np.savez(os.path.join(processed_data_path, \n",
    "                          'imputed-normed-ep' + '_' + str(n_sample_hour) + \\\n",
    "                          '_' + str(n_full_hour) + '.npz'), \n",
    "             ep_data = ep_data_withr, ep_tdata = ep_tdata_withr,\n",
    "             ep_data_masking = ep_data_masking_withr, \n",
    "             ep_tdata_masking = ep_tdata_masking_withr,\n",
    "             y_icd9 = y_icd9, y_mor = y_mor,adm_features_all=adm_features_all, adm_labels_all=adm_labels_all,y_los=y_los)\n",
    "#     , y_icd9_subcat=y_icd9_subcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.mean(y_mor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imputed_data = np.load('../../Data/admdata_17f/24hrs_raw/series/imputed-normed-ep_1_24.npz')\n",
    "# y_icd9 = imputed_data['y_icd9']\n",
    "# adm_labels_all = imputed_data['adm_labels_all']\n",
    "\n",
    "print('make splits')\n",
    "# make 5-fold cv splits if file not exists\n",
    "def make_splits_on(y_mor, foldn):\n",
    "    folds_ep_mor = []\n",
    "    for i in range(1):\n",
    "        folds_ep_mor.append(make_splits(y_mor, foldn))\n",
    "    return folds_ep_mor\n",
    "\n",
    "def gen_folds_ids(foldn, fold_file_path, **kwargs):\n",
    "    # generate folds based on label sets\n",
    "    folds = {}\n",
    "    print(list(kwargs.items()))\n",
    "    for labelname, (labelarray, is_multi_task) in kwargs.items():\n",
    "        assert len(labelarray.shape) > 1\n",
    "        folds[labelname] = []\n",
    "        if is_multi_task:\n",
    "            for ln in range(labelarray.shape[1]):\n",
    "                tempy = labelarray[:, ln]\n",
    "                try:\n",
    "                    lnfold = make_splits_on(tempy, foldn)\n",
    "                except:\n",
    "                    print('pass {0} {1}'.format(labelname, ln))\n",
    "                    lnfold = None\n",
    "                folds[labelname].append(lnfold)\n",
    "        else:\n",
    "            folds[labelname].append(make_splits_on(labelarray, foldn))\n",
    "    np.savez(fold_file_path, **folds)\n",
    "    return folds\n",
    "\n",
    "def get_standardize_stats_for_training(ep_tdata, ep_tdata_masking, adm_features_all, training_ids):\n",
    "    trainset = ep_tdata[training_ids]\n",
    "    trainset_masking = ep_tdata_masking[training_ids]\n",
    "    train_admfeatures = adm_features_all[training_ids]\n",
    "    id_num = trainset.shape[0]\n",
    "    dim = trainset.shape[2]\n",
    "    stats = np.empty((dim, 2)) * np.nan\n",
    "    for d in range(dim):\n",
    "        dim_values = trainset[:,:,d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        stats[d,:] = np.array([dim_mean, dim_std])\n",
    "    nsdim = adm_features_all.shape[1]\n",
    "    nsstats = np.empty((nsdim, 2)) * np.nan\n",
    "    for d in range(nsdim):\n",
    "        dim_values = train_admfeatures[:, d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        nsstats[d,:] = np.array([dim_mean, dim_std])\n",
    "    return stats, nsstats\n",
    "\n",
    "def get_standardize_stats_for_training_missing(ep_tdata, ep_tdata_masking, adm_features_all, training_ids):\n",
    "    trainset = np.concatenate(ep_tdata[training_ids])\n",
    "    trainset_masking = np.concatenate(ep_tdata_masking[training_ids])\n",
    "    train_admfeatures = adm_features_all[training_ids]\n",
    "    id_num = trainset.shape[0]\n",
    "    dim = trainset.shape[1]\n",
    "    stats = np.empty((dim, 2)) * np.nan\n",
    "    for d in range(dim):\n",
    "        dim_masking = trainset_masking[:,d].flatten()\n",
    "        dim_values = trainset[:,d].flatten()[np.where(dim_masking==1)]\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        stats[d,:] = np.array([dim_mean, dim_std])\n",
    "    nsdim = adm_features_all.shape[1]\n",
    "    nsstats = np.empty((nsdim, 2)) * np.nan\n",
    "    for d in range(nsdim):\n",
    "        dim_values = train_admfeatures[:, d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        nsstats[d,:] = np.array([dim_mean, dim_std])\n",
    "    return stats, nsstats\n",
    "\n",
    "def get_standardize_stats_for_folds(folds, stdfunc, ep_tdata, ep_tdata_masking, adm_features_all):\n",
    "    statsdict = {}\n",
    "    for key, value in folds.items():\n",
    "        statsdict[key] = []\n",
    "        for folds_ids in value:\n",
    "            foldsstat = []\n",
    "            for folds_ep_mor in folds_ids:\n",
    "                foldsn = folds_ep_mor.shape[0]\n",
    "                stats = []\n",
    "                ep_tdata_stdized_list = []\n",
    "                for foldn in range(foldsn):\n",
    "                    training_ids = folds_ep_mor[foldn,0]\n",
    "                    stat, nsstat = stdfunc(ep_tdata=ep_tdata, ep_tdata_masking=ep_tdata_masking, adm_features_all=adm_features_all, training_ids=training_ids)\n",
    "                    fstat = [stat[:, 0], stat[:, 1]]\n",
    "                    fnsstat = [nsstat[:, 0], nsstat[:, 1]]\n",
    "                    stats.append([fstat, fnsstat])\n",
    "                foldsstat.append(np.array(stats))\n",
    "            statsdict[key].append(foldsstat)\n",
    "    return statsdict\n",
    "\n",
    "def split_dataset(datasetfilename, ep_tdata_attr, ep_tdata_masking_attr, ep_adm_features_all_attr, aidwhere, statfunc, foldn, fold_filedir, **kwargs):\n",
    "    dataset = np.load(os.path.join(processed_data_path, datasetfilename + '.npz'), allow_pickle=True)\n",
    "    subdataset = {}\n",
    "    for key, value in dataset.items():\n",
    "        subdataset[key] = value[aidwhere]\n",
    "    sub_tdata = subdataset[ep_tdata_attr]\n",
    "    sub_masking = subdataset[ep_tdata_masking_attr]\n",
    "    sub_label_all = subdataset[ep_adm_features_all_attr]\n",
    "    sublabelset = {}\n",
    "    for key, (value, is_multi_task) in kwargs.items():\n",
    "        sublabelset[key] = (value[aidwhere], is_multi_task)\n",
    "    if not os.path.exists(fold_filedir):\n",
    "        os.makedirs(fold_filedir)\n",
    "    fold_file_path = os.path.join(fold_filedir, '%d-folds.npz' % foldn)\n",
    "    folds = gen_folds_ids(foldn=foldn, fold_file_path=fold_file_path, **sublabelset)\n",
    "    statsdict = get_standardize_stats_for_folds(folds, statfunc, ep_tdata=sub_tdata, ep_tdata_masking=sub_masking, adm_features_all=sub_label_all)\n",
    "    np.savez(os.path.join(fold_filedir, datasetfilename+'-stdized.npz'), **statsdict)\n",
    "#     if not os.path.exists(os.path.join(fold_filedir, datasetfilename+'.npz')):\n",
    "    np.savez(os.path.join(fold_filedir, datasetfilename+'.npz'), **subdataset)\n",
    "    print('finish', fold_filedir)\n",
    "\n",
    "from utils import getConnection\n",
    "\n",
    "# select ids in carevue\n",
    "sql = 'select distinct hadm_id from mimiciii.icustays where dbsource = \\'metavision\\' '\n",
    "sql += 'UNION select distinct hadm_id from mimiciii.transfers where dbsource = \\'metavision\\''\n",
    "conn = getConnection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(sql)\n",
    "res = cur.fetchall()\n",
    "mvaids = sorted([r[0] for r in res])\n",
    "mvaidset = set(mvaids)\n",
    "\n",
    "MVDIR = os.path.join(processed_data_path, 'mv')\n",
    "CVDIR = os.path.join(processed_data_path, 'cv')\n",
    "ALLDIR = processed_data_path\n",
    "data_all = np.load(os.path.join(working_path, 'DB_merged_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "allaids = np.array([t[0][-1] for t in data_all])\n",
    "mvwhere = np.array([aid in mvaidset for aid in allaids])\n",
    "cvwhere = ~mvwhere\n",
    "allwhere = np.logical_or(mvwhere, cvwhere)\n",
    "assert np.alltrue(allwhere)\n",
    "\n",
    "file_list = ['imputed-normed-ep_1_%d'%HRS, 'imputed-normed-ep_2_%d'%HRS]\n",
    "for filename in file_list:\n",
    "    for ids, dirname in zip([mvwhere, cvwhere, allwhere], [MVDIR, CVDIR, ALLDIR]):\n",
    "        split_dataset(\n",
    "            datasetfilename=filename,\n",
    "            ep_tdata_attr='ep_tdata',\n",
    "            ep_tdata_masking_attr='ep_tdata_masking',\n",
    "            ep_adm_features_all_attr='adm_features_all',\n",
    "            aidwhere=ids,\n",
    "            statfunc=get_standardize_stats_for_training,\n",
    "            foldn=5,\n",
    "            fold_filedir=dirname,\n",
    "#             folds_ep_icd9=(y_icd9, True),\n",
    "#             folds_ep_icd9_multi=(y_icd9, False),\n",
    "            folds_ep_mor=(adm_labels_all, True)\n",
    "        )\n",
    "        \n",
    "ep_datafilename = 'normed-ep-ratio'\n",
    "for ids, dirname in zip([mvwhere, cvwhere, allwhere], [MVDIR, CVDIR, ALLDIR]):\n",
    "    split_dataset(\n",
    "        datasetfilename=ep_datafilename,\n",
    "        ep_tdata_attr='X_t',\n",
    "        ep_tdata_masking_attr='X_t_mask',\n",
    "        ep_adm_features_all_attr='adm_features_all',\n",
    "        aidwhere=ids,\n",
    "        statfunc=get_standardize_stats_for_training_missing,\n",
    "        foldn=5,\n",
    "        fold_filedir=dirname,\n",
    "#         folds_ep_icd9=(y_icd9, True),\n",
    "#         folds_ep_icd9_multi=(y_icd9, False),\n",
    "        folds_ep_mor=(adm_labels_all, True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check some plot\n",
    "k = 4\n",
    "\n",
    "# pao2 / fio2\n",
    "checkx = np.load(os.path.join(processed_data_path, 'imputed-normed-ep_1_%d.npz'%HRS), allow_pickle=True)['ep_tdata']\n",
    "checkidx = np.random.randint(checkx.shape[0])\n",
    "heart_rate = checkx[checkidx, :, k]\n",
    "print(heart_rate)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "plt.plot(heart_rate)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
