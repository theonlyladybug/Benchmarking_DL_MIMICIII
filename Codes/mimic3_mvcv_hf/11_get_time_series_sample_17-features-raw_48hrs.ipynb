{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "# from sklearn.cross_validation import StratifiedShuffleSplit, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sys.path.append(\"..\")\n",
    "# from dataprocessing.util import make_splits\n",
    "\n",
    "def try_making_splits(y, nfold, test_ratio=None):\n",
    "    '''\n",
    "    y: n*n_class\n",
    "        tries to find n splits, where:\n",
    "        size of (train, valid, test) is (nfold-2, 1, 1)\n",
    "        # of samples for one class is (>=1/2, >=0.5*ratio, >=0.5*ratio)\n",
    "    '''\n",
    "    idx_list = np.empty([nfold, 3], dtype=object)\n",
    "    if test_ratio is None:\n",
    "        test_ratio = 1.0 / nfold\n",
    "    n_samples, n_classes = y.shape\n",
    "    i_class_least = np.argmin(np.sum(y, axis=0))\n",
    "    i_trial = 0\n",
    "    print('\\nnew try: ', i_trial,)\n",
    "    cnt = 0\n",
    "    while i_trial < nfold:\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print('{} trials'.format(cnt))\n",
    "        success_flag = True\n",
    "        ss = StratifiedShuffleSplit(n_splits=1,\n",
    "                                    test_size=test_ratio)\n",
    "        for idx_trva, idx_te in ss.split(np.zeros(len(y[:, i_class_least])), y[:, i_class_least]):  # length is only 1 !\n",
    "            for i_class in range(n_classes):\n",
    "                te_percent = 1.0 * np.sum(y[idx_te, i_class]) / np.sum(y[:, i_class])\n",
    "                trva_percent = 1.0 * np.sum(y[idx_trva, i_class]) / np.sum(y[:, i_class])\n",
    "                if te_percent < 0.5 * test_ratio or \\\n",
    "                                trva_percent < 0.5 + 0.5 * test_ratio:\n",
    "                    success_flag = False\n",
    "                    break\n",
    "            if not success_flag:\n",
    "                break\n",
    "        if not success_flag:\n",
    "            continue\n",
    "        cnt2 = 0\n",
    "        while cnt2 < 1000:\n",
    "            cnt2 += 1\n",
    "            success_flag = True\n",
    "            ss2 = StratifiedShuffleSplit(n_splits=1,\n",
    "                                         test_size=test_ratio * n_samples / len(idx_trva))\n",
    "            for idx_tr_ss2, idx_va_ss2 in ss2.split(np.zeros(len(idx_trva)), y[idx_trva, i_class_least]):  # length is only 1 !\n",
    "                idx_tr = idx_trva[idx_tr_ss2]\n",
    "                idx_va = idx_trva[idx_va_ss2]\n",
    "                for i_class in range(n_classes):\n",
    "                    tr_percent = 1.0 * np.sum(y[idx_tr, i_class]) / np.sum(y[:, i_class])\n",
    "                    va_percent = 1.0 * np.sum(y[idx_va, i_class]) / np.sum(y[:, i_class])\n",
    "                    if va_percent < 0.5 * test_ratio or \\\n",
    "                                    tr_percent < 0.5:\n",
    "                        success_flag = False\n",
    "                        break\n",
    "                if not success_flag:\n",
    "                    break\n",
    "            if not success_flag:\n",
    "                continue\n",
    "        if not success_flag:\n",
    "            continue\n",
    "        idx_list[i_trial] = [idx_tr, idx_va, idx_te]\n",
    "        i_trial += 1\n",
    "    return idx_list\n",
    "\n",
    "\n",
    "def make_splits(y, nfold):\n",
    "    if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "        return try_making_splits(y, nfold)\n",
    "    assert nfold > 2\n",
    "    skf = StratifiedKFold(nfold, shuffle=True, random_state=0)\n",
    "    idx_trva_list = []\n",
    "    idx_te_list = []\n",
    "    for idx_tr, idx_te in skf.split(np.zeros(np.array(y).flatten().shape[0]), np.array(y).flatten()):\n",
    "        idx_trva_list.append(idx_tr)\n",
    "        idx_te_list.append(idx_te)\n",
    "\n",
    "    idx_list = np.empty([nfold, 3], dtype=object)\n",
    "    for i in range(nfold):\n",
    "        idx_list[i][0] = np.setdiff1d(idx_trva_list[i], idx_te_list[(i + 1) % nfold], True)\n",
    "        idx_list[i][1] = idx_te_list[(i + 1) % nfold]\n",
    "        idx_list[i][2] = idx_te_list[i]\n",
    "    return idx_list\n",
    "\n",
    "# def get_icd9_subcat_label(icd9_str):\n",
    "#     ss = icd9_str.split('.')[0]\n",
    "#     idx_lb = max(np.where(ss >= subcat_lbs)[0])\n",
    "#     idx_ub = min(np.where(ss[:4] <= subcat_ubs)[0])\n",
    "#     if idx_lb != idx_ub:\n",
    "#         print(idx_lb, idx_ub, icd9_str, ss)\n",
    "#     #assert idx_lb == idx_ub\n",
    "#     return idx_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Main ####\n",
    "# DATA_NAME = 'mimic319k48h'\n",
    "# Settings for task, model, path, etc\n",
    "# working_path = r'../..'\n",
    "HRS = 48\n",
    "\n",
    "working_path = '/media/data/mimic/hf_admdata_17f/%dhrs_raw/' % HRS\n",
    "# raw_data_path = os.path.join(working_path, 'data', DATA_NAME, 'raw')\n",
    "# processed_data_path = os.path.join(working_path, 'data', DATA_NAME)\n",
    "raw_data_path = working_path\n",
    "processed_data_path = os.path.join(working_path, 'series')\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "\n",
    "LAB_EVENTS_IDX = np.array([0,1,2,3,4,5,6,7,9,10,11,12,13,14]) # labevents and chartevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data file\n",
      "load icd9 label file\n",
      "load mor label file\n",
      "load admission features\n",
      "load mortality labels\n",
      "# of samples: 31912\n",
      "[]\n",
      "# of samples > 48 hours: 31912\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "print('load data file')\n",
    "data_all = np.empty([0], dtype=object)\n",
    "for datanpz_file_name in ['DB_merged_%dhrs.npy' % HRS]:\n",
    "    datanpz_file_pathname = os.path.join(raw_data_path,\n",
    "                                         datanpz_file_name)\n",
    "    data_all = np.concatenate((data_all, np.load(datanpz_file_pathname, allow_pickle=True)))\n",
    "\n",
    "print('load icd9 label file')\n",
    "label_icd9_all = np.empty([0], dtype=object)\n",
    "for label_icd9_npz_file_name in ['ICD9-%dhrs.npy' % HRS]:\n",
    "    label_icd9_npz_file_pathname = os.path.join(raw_data_path, \n",
    "                                                label_icd9_npz_file_name)\n",
    "    label_icd9_all = np.concatenate((label_icd9_all, \n",
    "                                    np.load(label_icd9_npz_file_pathname, allow_pickle=True)))\n",
    "\n",
    "# print('load icd9 subcat list file')\n",
    "# subcat_lbs = []\n",
    "# subcat_ubs = []\n",
    "# with open(os.path.join(raw_data_path, 'ICD9_subcat.csv'), 'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         subcat_id, subcat_lb, subcat_ub = line.split(',')\n",
    "#         subcat_lbs.append(subcat_lb)\n",
    "#         subcat_ubs.append(subcat_ub)\n",
    "#     subcat_lbs = np.array(subcat_lbs)\n",
    "#     subcat_ubs = np.array(subcat_ubs)\n",
    "\n",
    "print('load mor label file')\n",
    "label_mor_all = None\n",
    "for label_mor_npz_file_name in ['AGE_LOS_MORTALITY_%dhrs.npy' % HRS]:\n",
    "    label_mor_npz_file_pathname = os.path.join(raw_data_path,\n",
    "                                               label_mor_npz_file_name)\n",
    "    if label_mor_all is None:\n",
    "        label_mor_all = np.load(label_mor_npz_file_pathname, allow_pickle=True)\n",
    "    else:\n",
    "        label_mor_all = np.concatenate((label_mor_all, \n",
    "                                        np.load(label_mor_npz_file_pathname, allow_pickle=True)))\n",
    "        \n",
    "print('load admission features')\n",
    "adm_features_all = np.load(os.path.join(raw_data_path, 'ADM_FEATURES_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "\n",
    "print('load mortality labels')\n",
    "adm_labels_all = np.load(os.path.join(raw_data_path, 'ADM_LABELS_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "\n",
    "N_all = len(data_all)\n",
    "print('# of samples:', N_all)\n",
    "# get per-frame samples;\n",
    "# imputed-normed-ep (imputation here):    \n",
    "#               ep_tdata_raw, ep_tdata: N * [ti * D]\n",
    "#               ep_tdata_mean, ep_tdata_std: D\n",
    "# normed-ep:    X_t, X_t_mask, deltaT_t: N * [ti * D]\n",
    "#               T_t: N * [ti]\n",
    "X_raw_p48 = np.array([np.array(xx, dtype=float)[:,:-2] for xx in data_all])\n",
    "tsraw_p48 = np.array([np.array(xx, dtype=float)[:,-2] for xx in data_all])\n",
    "del data_all\n",
    "\n",
    "idx_x = np.where([(tt[-1] - tt[0]) > 1.0*60*60*HRS for tt in tsraw_p48])[0]\n",
    "idx_x2 = np.where([(tt[-1] - tt[0]) <= 1.0*60*60*HRS for tt in tsraw_p48])[0]\n",
    "print(idx_x2)\n",
    "N = len(idx_x)\n",
    "print('# of samples > %s hours:' % (HRS), N)\n",
    "assert N_all == N\n",
    "X_raw = X_raw_p48[idx_x]\n",
    "tsraw = tsraw_p48[idx_x]\n",
    "label_icd9_all = label_icd9_all[idx_x]\n",
    "label_mor_all = label_mor_all[idx_x]\n",
    "adm_features_all = adm_features_all[idx_x]\n",
    "adm_labels_all = adm_labels_all[idx_x]\n",
    "\n",
    "for i_n in range(N):\n",
    "    #print i_n\n",
    "    if i_n % 20 == 0:\n",
    "        print('.', end='')\n",
    "        sys.stdout.flush()\n",
    "    for i_t in range(len(X_raw[i_n])):\n",
    "        for i_d in range(len(X_raw[i_n][i_t])):\n",
    "            if X_raw[i_n][i_t][i_d] is None:\n",
    "                X_raw[i_n][i_t][i_d] = np.nan\n",
    "X_raw_all = np.concatenate(X_raw)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get mr and kept idx\n"
     ]
    }
   ],
   "source": [
    "# remove the columns with less observations\n",
    "print('get mr and kept idx')\n",
    "val_mr = np.sum(np.isnan(X_raw_all), axis=0) * 1.0 / X_raw_all.shape[0]\n",
    "keep_val_idx = val_mr < 1-5e-4\n",
    "keep_val_idx_list = np.where(keep_val_idx)\n",
    "X_raw_all_kept = X_raw_all[:,keep_val_idx]\n",
    "X_raw_kept = np.array([xx[:, keep_val_idx] for xx in X_raw])\n",
    "lab_events_idx = LAB_EVENTS_IDX\n",
    "\n",
    "del X_raw_all\n",
    "del X_raw\n",
    "\n",
    "# X_raw_all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aid': 16,\n",
       " 'bilirubin_level': 14,\n",
       " 'body_temperature': 5,\n",
       " 'fio2': 7,\n",
       " 'gcseyes': 2,\n",
       " 'gcsmotor': 1,\n",
       " 'gcsverbal': 0,\n",
       " 'heart_rate': 4,\n",
       " 'pao2': 6,\n",
       " 'potassium_level_mean': 13,\n",
       " 'serum_bicarbonate_level_mean': 11,\n",
       " 'serum_urea_nitrogen_level': 9,\n",
       " 'sodium_level_mean': 12,\n",
       " 'systolic_blood_pressure_abp_mean': 3,\n",
       " 'timestamp': 15,\n",
       " 'urinary_output': 8,\n",
       " 'white_blood_cells_count_mean': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_feature_colids = np.load(os.path.join('/media/data/mimic/hf_admdata_17f/raw/', 'map_feature_colids.npy'), allow_pickle=True).tolist()\n",
    "map_feature_colids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:36: RuntimeWarning: All-NaN axis encountered\n",
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: All-NaN slice encountered\n",
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:38: RuntimeWarning: Mean of empty slice\n",
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: All-NaN axis encountered\n",
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: All-NaN slice encountered\n",
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: All-NaN axis encountered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "non_series_dir = os.path.join(processed_data_path, '../non_series')\n",
    "if not os.path.exists(non_series_dir):\n",
    "    os.makedirs(non_series_dir)\n",
    "# dirtyhack: manually add mean/max/min for features, and keep the final results same with what we use for 17 features\n",
    "# gcsxxx: min: 3*1\n",
    "# sbp, heartrate, bodytemp, ...: max/min: 9*2\n",
    "# pao2, fio2: min/max/mean: 2*3\n",
    "# urine: sum: 1*1\n",
    "# static features! 5*1\n",
    "min_list = list(map(lambda x: map_feature_colids[x], ['gcsverbal', 'gcsmotor', 'gcseyes']))\n",
    "minmax_list = list(map(lambda x: map_feature_colids[x], ['systolic_blood_pressure_abp_mean', 'heart_rate', 'body_temperature', 'serum_urea_nitrogen_level', 'white_blood_cells_count_mean', 'serum_bicarbonate_level_mean', 'sodium_level_mean', 'potassium_level_mean', 'bilirubin_level']))\n",
    "minmaxavg_list = list(map(lambda x: map_feature_colids[x], ['pao2', 'fio2']))\n",
    "sum_list = list(map(lambda x: map_feature_colids[x], ['urinary_output']))\n",
    "# adm_features_all\n",
    "total_featuren = len(min_list)*1 + len(minmax_list)*2 + len(minmaxavg_list)*3 + len(sum_list)*1 + adm_features_all.shape[1]\n",
    "hrs_mean_array = np.full((N, total_featuren), np.nan)\n",
    "for i in range(N):\n",
    "    if i % 20 == 0:\n",
    "        print('.', end='')\n",
    "        sys.stdout.flush()\n",
    "    tsraw[i] = tsraw[i].flatten()\n",
    "    t = 0\n",
    "    while t < len(tsraw[i]) and tsraw[i][t] - tsraw[i][0] <= HRS * 3600.0:\n",
    "        t = t + 1\n",
    "    fstart = 0\n",
    "    # min_list\n",
    "    tempmin = np.nanmin(X_raw_kept[i][0:t, min_list], axis=0)\n",
    "    hrs_mean_array[i, fstart:fstart+len(min_list)*1] = tempmin\n",
    "    fstart += len(min_list)*1\n",
    "    # minmax_list\n",
    "    tempmin = np.nanmin(X_raw_kept[i][0:t, minmax_list], axis=0)\n",
    "    tempmax = np.nanmax(X_raw_kept[i][0:t, minmax_list], axis=0)\n",
    "    hrs_mean_array[i, fstart:fstart+len(minmax_list)*2] = np.concatenate([tempmin, tempmax])\n",
    "    fstart += len(minmax_list)*2\n",
    "    # mimmaxavg_list\n",
    "    tempmin = np.nanmin(X_raw_kept[i][0:t, minmaxavg_list], axis=0)\n",
    "    tempmax = np.nanmax(X_raw_kept[i][0:t, minmaxavg_list], axis=0)\n",
    "    tempavg = np.nanmean(X_raw_kept[i][0:t, minmaxavg_list], axis=0)\n",
    "    hrs_mean_array[i, fstart:fstart+len(minmaxavg_list)*3] = np.concatenate([tempmin, tempmax, tempavg])\n",
    "    fstart += len(minmaxavg_list)*3\n",
    "    # sum_list\n",
    "    tempsum = np.nansum(X_raw_kept[i][0:t, sum_list], axis=0)\n",
    "    hrs_mean_array[i, fstart:fstart+len(sum_list)*1] = tempsum\n",
    "    fstart += len(sum_list)*1\n",
    "    # static list\n",
    "    hrs_mean_array[i, fstart:] = adm_features_all[i, :]\n",
    "\n",
    "hrs_mean_labels = adm_labels_all\n",
    "np.savez(os.path.join(non_series_dir, 'tsmean_%dhrs.npz' % HRS), hrs_mean_array=hrs_mean_array, hrs_mean_labels=hrs_mean_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get mean and std for tdata\n",
      "get X_new and t_new\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "print('get mean and std for tdata')\n",
    "n_temporal_var = X_raw_all_kept.shape[1]    # last frame is time t in seconds\n",
    "ep_tdata_mean = np.nanmean(X_raw_all_kept, axis=0)\n",
    "ep_tdata_std = np.nanstd(X_raw_all_kept, axis=0)\n",
    "del X_raw_all_kept\n",
    "\n",
    "# get ep data with mask and deltaT\n",
    "# 0-mean, 1-std, merge observations within 5 mins\n",
    "merging_mins = 5\n",
    "print('get X_new and t_new')\n",
    "X_new = np.empty([N], dtype=object)\n",
    "t_new = np.empty([N], dtype=object)\n",
    "for i in range(N):\n",
    "    if i % 20 == 0:\n",
    "        print('.',end='')\n",
    "        sys.stdout.flush()\n",
    "    tsraw[i] = tsraw[i].flatten()\n",
    "    t = 0\n",
    "    X_new[i] = []\n",
    "    t_new[i] = []\n",
    "    while t < len(tsraw[i]):\n",
    "        t1 = t+1\n",
    "        while t1 < len(tsraw[i]) and tsraw[i][t1] - tsraw[i][t] <= merging_mins*60:\n",
    "            t1 += 1\n",
    "        # merge [t:t1]\n",
    "#         X_new[i].append(\n",
    "#             (np.nanmean(X_raw_kept[i][t:t1,:], axis=0) - ep_tdata_mean) \\\n",
    "#                 /ep_tdata_std\n",
    "#             )\n",
    "        # Here we do not normalize the data!!!\n",
    "        X_new[i].append(\n",
    "            np.nanmean(X_raw_kept[i][t:t1,:], axis=0)\n",
    "            )\n",
    "        # X_new[i].append(np.nanmean(X_raw_kept[i][t:t1,:], axis=0))\n",
    "        t_new[i].append(int((tsraw[i][t1-1]+tsraw[i][t])/2))\n",
    "        t = t1\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get X_t, mask, etc\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "print('get X_t, mask, etc')\n",
    "X_t = np.empty([N], dtype=object)        # N * [t*d]\n",
    "X_t_mask = np.empty([N], dtype=object)   # N * [t*d]\n",
    "T_t = t_new                                 # N * [t]\n",
    "deltaT_t = np.empty([N], dtype=object)   # N * [t*d]\n",
    "for i in range(N):\n",
    "    if i % 20 == 0:\n",
    "        print('.',end='')\n",
    "        sys.stdout.flush()\n",
    "    X_t[i] = np.vstack(X_new[i])\n",
    "    X_t_mask[i] = 1-np.isnan(X_t[i]).astype('int8')\n",
    "    X_t[i][np.isnan(X_t[i])] = 0\n",
    "    deltaT_t[i] = np.zeros_like(X_t[i], dtype=int)\n",
    "    deltaT_t[i][0,:] = 0\n",
    "    for i_t in range(1, len(T_t[i])):\n",
    "        deltaT_t[i][i_t,:] = T_t[i][i_t] - T_t[i][i_t-1] + \\\n",
    "            (1-X_t_mask[i][i_t-1,:]) * deltaT_t[i][i_t-1,:]\n",
    "print('done!')\n",
    "del X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get labels\n",
      "# of class, subcat:\n"
     ]
    }
   ],
   "source": [
    "# extract subcat labels\n",
    "# for i_n, label_i in enumerate(label_icd9_all):\n",
    "#     for i_li, label_vec in enumerate(label_i):\n",
    "#         subcat = get_icd9_subcat_label(label_vct[2])\n",
    "#         label_i[i_li].append(subcat)\n",
    "#     label_icd9_all[i_n] = label_i\n",
    "        \n",
    "# get labels\n",
    "print('get labels')\n",
    "class_icd9_counts = np.bincount(\n",
    "    np.concatenate(label_icd9_all)[:,3].astype(int))\n",
    "class_icd9_list = np.where(class_icd9_counts > 10)[0]\n",
    "class_icd9_list.sort()\n",
    "\n",
    "# class_icd9_subcat_counts = np.bincount(\n",
    "#     np.concatenate(label_icd9_all)[:,4].astype(int))\n",
    "# class_icd9_subcat_list = np.where(class_icd9_subcat_counts >= 200)[0]\n",
    "# class_icd9_subcat_list.sort()\n",
    "\n",
    "n_class_icd9 = class_icd9_list.shape[0]\n",
    "# n_class_icd9_subcat = class_icd9_subcat_list.shape[0]\n",
    "y_icd9 = np.zeros([N, n_class_icd9], dtype=int)\n",
    "# y_icd9_subcat = np.zeros([N, n_class_icd9_subcat], dtype=int)\n",
    "for i_n, label_i in enumerate(label_icd9_all):\n",
    "        for label_vec in label_i:\n",
    "            class_idx = np.array(\n",
    "                [cl == label_vec[3] for cl in class_icd9_list],\n",
    "                dtype=bool)\n",
    "            y_icd9[i_n][class_idx] = 1\n",
    "#             subcat_idx = np.array(\n",
    "#                 [cl == label_vec[4] for cl in class_icd9_subcat_list],\n",
    "#                 dtype=bool)\n",
    "#             y_icd9_subcat[i_n][subcat_idx] = 1\n",
    "\n",
    "y_mor = np.expand_dims(np.array(label_mor_all[:,4], dtype=int), axis=1)\n",
    "age_days = label_mor_all[:, 2]\n",
    "y_los = label_mor_all[:, 3]\n",
    "            \n",
    "# print('# of class, subcat:', n_class_icd9, n_class_icd9_subcat)\n",
    "print('# of class, subcat:')\n",
    "\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep-stats.npz'), \n",
    "         class_icd9_list=class_icd9_list, \n",
    "         class_icd9_counts=class_icd9_counts,\n",
    "#          class_icd9_subcat_list=class_icd9_subcat_list,\n",
    "#          class_icd9_subcat_counts=class_icd9_subcat_counts,\n",
    "         keep_val_idx_list=keep_val_idx_list, \n",
    "         ep_tdata_mean=ep_tdata_mean, ep_tdata_std=ep_tdata_std,\n",
    "         n_class_icd9=n_class_icd9, \n",
    "#          n_class_icd9_subcat=n_class_icd9_subcat,\n",
    "         N=N, val_mr=val_mr, idx_x=idx_x, age_days=age_days)\n",
    "\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep.npz'), \n",
    "         X_t=X_t,X_t_mask=X_t_mask,T_t=T_t,deltaT_t=deltaT_t,\n",
    "         y_icd9=y_icd9, y_mor=y_mor, adm_features_all=adm_features_all, adm_labels_all=adm_labels_all, y_los=y_los)\n",
    "# , y_icd9_subcat=y_icd9_subcat)\n",
    "\n",
    "del X_t, X_t_mask, deltaT_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get X_miss 2 48\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get X_imputed\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:38: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get ep_tdata\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get X_miss 1 48\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get X_imputed\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n",
      "get ep_tdata\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "# get first N hours data\n",
    "# one data sample for one patient\n",
    "# hours_list = [(2, 24), (1, 24), (1, 48), (2, 48)]\n",
    "hours_list = [(2, HRS), (1, HRS)]\n",
    "for n_sample_hour, n_full_hour in hours_list:\n",
    "    print('get X_miss', n_sample_hour, n_full_hour)\n",
    "    #n_sample_hour = 2\n",
    "    #n_full_hour = HRS\n",
    "    n_time_step = int(n_full_hour / n_sample_hour)\n",
    "    # get X_miss first from X_raw_all_kept and tsraw, (sampled)\n",
    "    X_miss = np.empty([N], dtype = object)\n",
    "    T_miss = np.zeros([N], dtype = int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        T_miss[i_n] = math.ceil(\n",
    "            (tsraw[i_n][-1]-tsraw[i_n][0])*1.0/(60*60*n_sample_hour))\n",
    "        X_miss[i_n] = np.zeros([T_miss[i_n], n_temporal_var], dtype=float)\n",
    "        for i_t in range(T_miss[i_n]):\n",
    "            t_idx = np.logical_and(\n",
    "                (tsraw[i_n]-tsraw[i_n][0]) >= i_t*(60*60*n_sample_hour),\n",
    "                (tsraw[i_n]-tsraw[i_n][0]) <= (1+i_t) * (60*60*n_sample_hour))\n",
    "            X_raw_thist = X_raw_kept[i_n][t_idx, :]\n",
    "            # Here we do not normalize the data!!!\n",
    "#             X_miss[i_n][i_t,:] = \\\n",
    "#                 (np.nanmean(X_raw_thist, axis=0) - ep_tdata_mean) / ep_tdata_std\n",
    "            X_miss[i_n][i_t,:] = np.nanmean(X_raw_thist, axis=0)\n",
    "    print('done!')\n",
    "    # X_imputed: do forward/backward imputing from X_miss for lab events\n",
    "    #            do mean imputing for other events\n",
    "    print('get X_imputed')\n",
    "    X_imputed = deepcopy(X_miss)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        i_n_mean = np.nanmean(X_imputed[i_n], axis=0)\n",
    "        for i_t in range(1, T_miss[i_n]):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    if keep_val_idx_list[0][i_d] in lab_events_idx:\n",
    "                        X_imputed[i_n][i_t, i_d] = X_imputed[i_n][i_t-1, i_d]\n",
    "        for i_t in range(T_miss[i_n]-2, -1, -1):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    if keep_val_idx_list[0][i_d] in lab_events_idx:\n",
    "                        X_imputed[i_n][i_t, i_d] = X_imputed[i_n][i_t+1, i_d]\n",
    "        # X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "        # Here we use mean value of each feature in current time series to impute nans\n",
    "        for i_t in range(0, T_miss[i_n]):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    X_imputed[i_n][i_t, i_d] = i_n_mean[i_d]\n",
    "        # for values which are still none, just impute with 0\n",
    "#         X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "    print('done!')\n",
    "        \n",
    "    # get first # hours, for both data and masking\n",
    "    print('get ep_tdata')\n",
    "    ep_tdata = np.zeros([N, n_time_step, n_temporal_var], dtype=float)\n",
    "    ep_tdata_masking = np.zeros_like(ep_tdata, dtype=int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        xx_imp = X_imputed[i_n]\n",
    "        xx_mis = X_miss[i_n]\n",
    "        tt_min = min(n_time_step, len(xx_imp))\n",
    "        assert tt_min > 0\n",
    "        ep_tdata[i_n, :tt_min, :] = xx_imp[:tt_min, :]\n",
    "        ep_tdata[i_n, tt_min:, :] = ep_tdata[i_n, tt_min-1, :][None, :]\n",
    "        ep_tdata_masking[i_n, :tt_min, :] = \\\n",
    "            (~np.isnan(xx_mis[:tt_min, :])).astype(int)\n",
    "    print('done!')\n",
    "\n",
    "    ep_data = np.reshape(ep_tdata, [N, n_time_step*n_temporal_var])\n",
    "    ep_data_masking = np.reshape(ep_tdata_masking, [N, n_time_step*n_temporal_var])\n",
    "    \n",
    "    np.savez(os.path.join(processed_data_path, \n",
    "                          'imputed-normed-ep' + '_' + str(n_sample_hour) + \\\n",
    "                          '_' + str(n_full_hour) + '.npz'), \n",
    "             ep_data = ep_data, ep_tdata = ep_tdata,\n",
    "             ep_data_masking = ep_data_masking, \n",
    "             ep_tdata_masking = ep_tdata_masking,\n",
    "             y_icd9 = y_icd9, y_mor = y_mor,adm_features_all=adm_features_all, adm_labels_all=adm_labels_all,y_los=y_los)\n",
    "#     , y_icd9_subcat=y_icd9_subcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0968601153171\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_mor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make splits\n",
      "[('folds_ep_icd9', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 0, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), True)), ('folds_ep_icd9_multi', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 0, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), False)), ('folds_ep_mor', (array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]]), True))]\n",
      "\n",
      "new try:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/sklearn/cross_validation.py:552: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish ../../Data/admdata_17f/48hrs_raw/series/mv\n",
      "[('folds_ep_icd9', (array([[0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       [1, 0, 0, ..., 1, 1, 1],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1]]), True)), ('folds_ep_icd9_multi', (array([[0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       [1, 0, 0, ..., 1, 1, 1],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1]]), False)), ('folds_ep_mor', (array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]]), True))]\n",
      "\n",
      "new try:  0\n",
      "finish ../../Data/admdata_17f/48hrs_raw/series/cv\n",
      "[('folds_ep_icd9', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       ..., \n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), True)), ('folds_ep_icd9_multi', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       ..., \n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), False)), ('folds_ep_mor', (array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]]), True))]\n",
      "\n",
      "new try:  0\n",
      "finish ../../Data/admdata_17f/48hrs_raw/series\n",
      "[('folds_ep_icd9', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 0, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), True)), ('folds_ep_icd9_multi', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 0, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), False)), ('folds_ep_mor', (array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]]), True))]\n",
      "\n",
      "new try:  0\n",
      "finish ../../Data/admdata_17f/48hrs_raw/series/mv\n",
      "[('folds_ep_icd9', (array([[0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       [1, 0, 0, ..., 1, 1, 1],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1]]), True)), ('folds_ep_icd9_multi', (array([[0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       [1, 0, 0, ..., 1, 1, 1],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1]]), False)), ('folds_ep_mor', (array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]]), True))]\n",
      "\n",
      "new try:  0\n",
      "finish ../../Data/admdata_17f/48hrs_raw/series/cv\n",
      "[('folds_ep_icd9', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       ..., \n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), True)), ('folds_ep_icd9_multi', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       ..., \n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), False)), ('folds_ep_mor', (array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]]), True))]\n",
      "\n",
      "new try:  0\n",
      "finish ../../Data/admdata_17f/48hrs_raw/series\n",
      "[('folds_ep_icd9', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 0, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), True)), ('folds_ep_icd9_multi', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 0, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), False)), ('folds_ep_mor', (array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]]), True))]\n",
      "\n",
      "new try:  0\n",
      "finish ../../Data/admdata_17f/48hrs_raw/series/mv\n",
      "[('folds_ep_icd9', (array([[0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       [1, 0, 0, ..., 1, 1, 1],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1]]), True)), ('folds_ep_icd9_multi', (array([[0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       [1, 0, 0, ..., 1, 1, 1],\n",
      "       ..., \n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1]]), False)), ('folds_ep_mor', (array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]]), True))]\n",
      "\n",
      "new try:  0\n",
      "finish ../../Data/admdata_17f/48hrs_raw/series/cv\n",
      "[('folds_ep_icd9', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       ..., \n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), True)), ('folds_ep_icd9_multi', (array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       ..., \n",
      "       [1, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 1, ..., 1, 1, 1],\n",
      "       [0, 0, 1, ..., 0, 1, 0]]), False)), ('folds_ep_mor', (array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]]), True))]\n",
      "\n",
      "new try:  0\n",
      "finish ../../Data/admdata_17f/48hrs_raw/series\n"
     ]
    }
   ],
   "source": [
    "# imputed_data = np.load('../../Data/admdata_17f/24hrs_raw/series/imputed-normed-ep_1_24.npz')\n",
    "# y_icd9 = imputed_data['y_icd9']\n",
    "# adm_labels_all = imputed_data['adm_labels_all']\n",
    "\n",
    "print('make splits')\n",
    "# make 5-fold cv splits if file not exists\n",
    "def make_splits_on(y_mor, foldn):\n",
    "    folds_ep_mor = []\n",
    "    for i in range(1):\n",
    "        folds_ep_mor.append(make_splits(y_mor, foldn))\n",
    "    return folds_ep_mor\n",
    "\n",
    "def gen_folds_ids(foldn, fold_file_path, **kwargs):\n",
    "    # generate folds based on label sets\n",
    "    folds = {}\n",
    "    print(list(kwargs.items()))\n",
    "    for labelname, (labelarray, is_multi_task) in kwargs.items():\n",
    "        assert len(labelarray.shape) > 1\n",
    "        folds[labelname] = []\n",
    "        if is_multi_task:\n",
    "            for ln in range(labelarray.shape[1]):\n",
    "                tempy = labelarray[:, ln]\n",
    "                try:\n",
    "                    lnfold = make_splits_on(tempy, foldn)\n",
    "                except:\n",
    "                    print('pass {0} {1}'.format(labelname, ln))\n",
    "                    lnfold = None\n",
    "                folds[labelname].append(lnfold)\n",
    "        else:\n",
    "            folds[labelname].append(make_splits_on(labelarray, foldn))\n",
    "    np.savez(fold_file_path, **folds)\n",
    "    return folds\n",
    "\n",
    "def get_standardize_stats_for_training(ep_tdata, ep_tdata_masking, adm_features_all, training_ids):\n",
    "    trainset = ep_tdata[training_ids]\n",
    "    trainset_masking = ep_tdata_masking[training_ids]\n",
    "    train_admfeatures = adm_features_all[training_ids]\n",
    "    id_num = trainset.shape[0]\n",
    "    dim = trainset.shape[2]\n",
    "    stats = np.empty((dim, 2)) * np.nan\n",
    "    for d in range(dim):\n",
    "        dim_values = trainset[:,:,d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        stats[d,:] = np.array([dim_mean, dim_std])\n",
    "    nsdim = adm_features_all.shape[1]\n",
    "    nsstats = np.empty((nsdim, 2)) * np.nan\n",
    "    for d in range(nsdim):\n",
    "        dim_values = train_admfeatures[:, d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        nsstats[d,:] = np.array([dim_mean, dim_std])\n",
    "    return stats, nsstats\n",
    "\n",
    "def get_standardize_stats_for_training_missing(ep_tdata, ep_tdata_masking, adm_features_all, training_ids):\n",
    "    trainset = np.concatenate(ep_tdata[training_ids])\n",
    "    trainset_masking = np.concatenate(ep_tdata_masking[training_ids])\n",
    "    train_admfeatures = adm_features_all[training_ids]\n",
    "    id_num = trainset.shape[0]\n",
    "    dim = trainset.shape[1]\n",
    "    stats = np.empty((dim, 2)) * np.nan\n",
    "    for d in range(dim):\n",
    "        dim_masking = trainset_masking[:,d].flatten()\n",
    "        dim_values = trainset[:,d].flatten()[np.where(dim_masking==1)]\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        stats[d,:] = np.array([dim_mean, dim_std])\n",
    "    nsdim = adm_features_all.shape[1]\n",
    "    nsstats = np.empty((nsdim, 2)) * np.nan\n",
    "    for d in range(nsdim):\n",
    "        dim_values = train_admfeatures[:, d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        nsstats[d,:] = np.array([dim_mean, dim_std])\n",
    "    return stats, nsstats\n",
    "\n",
    "def get_standardize_stats_for_folds(folds, stdfunc, ep_tdata, ep_tdata_masking, adm_features_all):\n",
    "    statsdict = {}\n",
    "    for key, value in folds.items():\n",
    "        statsdict[key] = []\n",
    "        for folds_ids in value:\n",
    "            foldsstat = []\n",
    "            for folds_ep_mor in folds_ids:\n",
    "                foldsn = folds_ep_mor.shape[0]\n",
    "                stats = []\n",
    "                ep_tdata_stdized_list = []\n",
    "                for foldn in range(foldsn):\n",
    "                    training_ids = folds_ep_mor[foldn,0]\n",
    "                    stat, nsstat = stdfunc(ep_tdata=ep_tdata, ep_tdata_masking=ep_tdata_masking, adm_features_all=adm_features_all, training_ids=training_ids)\n",
    "                    fstat = [stat[:, 0], stat[:, 1]]\n",
    "                    fnsstat = [nsstat[:, 0], nsstat[:, 1]]\n",
    "                    stats.append([fstat, fnsstat])\n",
    "                foldsstat.append(np.array(stats))\n",
    "            statsdict[key].append(foldsstat)\n",
    "    return statsdict\n",
    "\n",
    "def split_dataset(datasetfilename, ep_tdata_attr, ep_tdata_masking_attr, ep_adm_features_all_attr, aidwhere, statfunc, foldn, fold_filedir, **kwargs):\n",
    "    dataset = np.load(os.path.join(processed_data_path, datasetfilename + '.npz'), allow_pickle=True)\n",
    "    subdataset = {}\n",
    "    for key, value in dataset.items():\n",
    "        subdataset[key] = value[aidwhere]\n",
    "    sub_tdata = subdataset[ep_tdata_attr]\n",
    "    sub_masking = subdataset[ep_tdata_masking_attr]\n",
    "    sub_label_all = subdataset[ep_adm_features_all_attr]\n",
    "    sublabelset = {}\n",
    "    for key, (value, is_multi_task) in kwargs.items():\n",
    "        sublabelset[key] = (value[aidwhere], is_multi_task)\n",
    "    if not os.path.exists(fold_filedir):\n",
    "        os.makedirs(fold_filedir)\n",
    "    fold_file_path = os.path.join(fold_filedir, '%d-folds.npz' % foldn)\n",
    "    folds = gen_folds_ids(foldn=foldn, fold_file_path=fold_file_path, **sublabelset)\n",
    "    statsdict = get_standardize_stats_for_folds(folds, statfunc, ep_tdata=sub_tdata, ep_tdata_masking=sub_masking, adm_features_all=sub_label_all)\n",
    "    np.savez(os.path.join(fold_filedir, datasetfilename+'-stdized.npz'), **statsdict)\n",
    "    if not os.path.exists(os.path.join(fold_filedir, datasetfilename+'.npz')):\n",
    "        np.savez(os.path.join(fold_filedir, datasetfilename+'.npz'), **subdataset)\n",
    "    print('finish', fold_filedir)\n",
    "\n",
    "from utils import getConnection\n",
    "\n",
    "# select ids in carevue\n",
    "sql = 'select distinct hadm_id from mimiciii.icustays where dbsource = \\'metavision\\' '\n",
    "sql += 'UNION select distinct hadm_id from mimiciii.transfers where dbsource = \\'metavision\\''\n",
    "conn = getConnection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(sql)\n",
    "res = cur.fetchall()\n",
    "mvaids = sorted([r[0] for r in res])\n",
    "mvaidset = set(mvaids)\n",
    "\n",
    "MVDIR = os.path.join(processed_data_path, 'mv')\n",
    "CVDIR = os.path.join(processed_data_path, 'cv')\n",
    "ALLDIR = processed_data_path\n",
    "data_all = np.load(os.path.join(working_path, 'DB_merged_%dhrs.npy' % HRS), allow_pickle=True)\n",
    "allaids = np.array([t[0][-1] for t in data_all])\n",
    "mvwhere = np.array([aid in mvaidset for aid in allaids])\n",
    "cvwhere = ~mvwhere\n",
    "allwhere = np.logical_or(mvwhere, cvwhere)\n",
    "assert np.alltrue(allwhere)\n",
    "\n",
    "file_list = ['imputed-normed-ep_1_%d'%HRS, 'imputed-normed-ep_2_%d'%HRS]\n",
    "for filename in file_list:\n",
    "    for ids, dirname in zip([mvwhere, cvwhere, allwhere], [MVDIR, CVDIR, ALLDIR]):\n",
    "        split_dataset(\n",
    "            datasetfilename=filename,\n",
    "            ep_tdata_attr='ep_tdata',\n",
    "            ep_tdata_masking_attr='ep_tdata_masking',\n",
    "            ep_adm_features_all_attr='adm_features_all',\n",
    "            aidwhere=ids,\n",
    "            statfunc=get_standardize_stats_for_training,\n",
    "            foldn=5,\n",
    "            fold_filedir=dirname,\n",
    "#             folds_ep_icd9=(y_icd9, True),\n",
    "#             folds_ep_icd9_multi=(y_icd9, False),\n",
    "            folds_ep_mor=(adm_labels_all, True)\n",
    "        )\n",
    "        \n",
    "ep_datafilename = 'normed-ep'\n",
    "for ids, dirname in zip([mvwhere, cvwhere, allwhere], [MVDIR, CVDIR, ALLDIR]):\n",
    "    split_dataset(\n",
    "        datasetfilename=ep_datafilename,\n",
    "        ep_tdata_attr='X_t',\n",
    "        ep_tdata_masking_attr='X_t_mask',\n",
    "        ep_adm_features_all_attr='adm_features_all',\n",
    "        aidwhere=ids,\n",
    "        statfunc=get_standardize_stats_for_training_missing,\n",
    "        foldn=5,\n",
    "        fold_filedir=dirname,\n",
    "#         folds_ep_icd9=(y_icd9, True),\n",
    "#         folds_ep_icd9_multi=(y_icd9, False),\n",
    "        folds_ep_mor=(adm_labels_all, True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check some plot\n",
    "k = 4\n",
    "\n",
    "# pao2 / fio2\n",
    "checkx = np.load(os.path.join(processed_data_path, 'imputed-normed-ep_1_%d.npz'%HRS), allow_pickle=True)['ep_tdata']\n",
    "checkidx = np.random.randint(checkx.shape[0])\n",
    "heart_rate = checkx[checkidx, :, k]\n",
    "print(heart_rate)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "plt.plot(heart_rate)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
